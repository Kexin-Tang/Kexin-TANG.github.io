[{"title":"AFK和CAP原则","url":"/2021/05/28/AFK%E5%92%8CCAP%E5%8E%9F%E5%88%99/","content":"CAP\n一致性(Consistency) – 在一个集群里，无论访问哪台机器，数据都是一致的。\n一致性引入了“主从复制”的概念。\n\n强一致性 – 只要可读，必须保证能读到最新的值\n弱一致性 – 在写完后一定的时间窗口内不能读到最新的，但是过了时间窗口后可以读到最新的值\n最终一致性 – 弱一致性的特例，只要最后的数据能保持一致/更新即可\n\n\n\n可用性(Availability) – 在可用节点上，能够提供正常的服务。\n分区容错性(Partition Tolerance) – 集群中某个节点的某个主机宕机，并不会影响整体的服务。\n\n这三个准则中只能同时满足其中两种。\n\n保证C：那么必须要等这条命令的修改执行到了所有服务器上，主从上都有这个修改，那么就必须等主服务器进行了命令传播后，才能回复客户端\n保证A：如果要保证A的话，那么一条命令的执行时间就必须在规定的范围内，不能太久，及时给客户端作出响应\n保证P：如果要保证P的话，那么一个节点坏了的时候需要有从服务器及时替上\n\n1. 如果保证CA，放弃P：要保持数据一致性且不会超时，那么主从机数量有限。但是这样宕机后的可容忍性下降，无法满足P。2. 如果保证CP，放弃A：保持数据一致性且容忍性高，那么需要多台机器，且每台机器的执行时间会比较久。但是这样就不一定能满足在有限时间内完成任务。3. 如果保证AP，放弃C：保持多台机器且要在一定时间内完成任务，那么就不一定能保证数据在有限时间内同步到这么多机器内，数据一致性可能被破坏。\n\n由于使用集群，肯定不能宕机导致服务崩溃，所以P必须要保证，而在A和C中，一般都会选择A，因为C可以通过最终一致性来实现。\nACID保证A和C的时候，就实现了ACID(原子性、一致性、隔离性和持久性)\nBASE保证A和P时，就实现了BASE。\n\n基本可用（Basically Available）\n软状态（Soft state）\n最终一致（Eventually consistent）\n\n它的思想是通过让系统放松对某一时刻数据一致性的要求来换取系统整体伸缩性和性能上改观。\n\nAFKAKF扩展立方体：这个立方体有三个轴线，每个轴线描述扩展性的一个维度，他们分别是产品、流程和团队：\n\nx轴：考虑高可用，一个节点的数据需要做备份，越大代表备份越多\ny轴：代表将一个节点的数据细分成多个模块，想微服务将业务上细分成多个模块\nz轴：代表当细分成了多个模块之后，一个模块的并发依然很大，还需要细分，那么就需要把一个模块的数据分成多台机器存储，但是需要知道数据存在了哪台服务器上，就需要算法计算在哪台机器\n\n\nx轴：在x轴方向上，做N个主机的全量镜像数据的副本，主redis与这些副本的关系为主从。主机可以对外提供read / write ，从机可以对外提供read（读写分离）。结合高可用， 可以解决单点故障和容量瓶颈的问题，只是解决了 read 的压力，而没有解决 write 的压力。\n\n\ny轴：在y轴方向上，可以把之前一台redis中的数据按照业务功能来拆分成不同的redis实例存储，并且每个redis实例都可以再次做x轴的镜像副本进行读写分离，当然，x轴和y轴之间不是必须要结合使用。y轴的拆分解决了容量瓶颈问题和数据访问压力的问题。\n\n\nz轴：如果y轴的某个redis实例过于臃肿，还可以把这个redis实例进行z轴的拆分，也就是把这个redis实例里面的数据按照一定规则查分。比如：取模，优先级等规则再次查分成多个redis，使得不同的数据出现在固定的redis里。\n\n三种模型A模型：算法写在每个客户端，如果需要修改算法，每个客户端都需要修改\nB模型：找一个代理，每个客户端访问先经过一个代理，代理做计算，然后访问具体机器\nC模型：服务器自身进行算法划分，redis的做法就是分了16384个槽(slot)，然后每台服务器各自占了其中一部分槽，如果key属于该槽，那么就由这条命令执行\n\nRAFT分布式一致性算法，一般用于主从服务器，主服务器挂掉之后如何选举。\n简单说一下实现，三个角色，leader（主） ， follower（从） ，candidate（参与投票的候选人）\n每个节点都有一个定时器，每个节点的过期时间不一样，如果一个节点的定时器归零了，那么这个节点就会成为candidate，然后让其他节点给自己投票，出现多个的话就会同时要票，如果没有超过半数就会重新选举，票是先到先得的，如果超过半数，那么就会成为新的leader节点，这只是在于leader节点挂了的话，才会出现定时器归零，如果leader没有挂掉，那么就会定期发送心跳包，follower节点接收到心跳包，会重新刷新定时器的时间，直到leader挂掉，才会出现定时器归零进行选举leader节点。\n","categories":["Redis","概念","分布式"],"tags":["分布式","概念","redis"]},{"title":"BIO、NIO和AIO","url":"/2021/05/17/BIO%E3%80%81NIO%E5%92%8CAIO/","content":"BIO同步阻塞IO。同步指的是多个IO请求会按顺序执行，阻塞指的是如果一个IO请求没有完成，就会一直等待，直到完成释放。\n\n图中fd代表 文件描述符。\nBIO的逻辑就是某个线程盯住某个特定的请求，没有请求就一直等，直到有请求并完成请求。\n\nNIONIO本身是基于事件驱动思想来完成的，其主要想解决的是BIO的大并发问题。在BIO中，会使用多线程，每个线程盯住一个资源；在NIO中使用单线程或少量多线程，多个资源复用一个线程。\n轮询\n会使用Linux的系统调用read来读取fd。仍然是使用类似循环的逻辑，不断查询i有没有请求？如果没有也不会傻等，而是换到下一个请求，所以是非阻塞的。在这种情况下，如果有n个IO，则需要调用n次系统调用。\n多路复用\n此时会使用Linux的系统调用select和read，但是此时不会调用n次系统调用。此时会先调用一次select记录下每个IO的请求与否，然后把这个信息返回。最后只调用read处理有请求的。这个过程类似于中断。\n共享内存\n上一种方法中仍然要进行文件的传输，而可以使用一个共享内存。kernel获取请求情况，然后标记在共享内存中，线程直接读取共享内存的状态即可，不用传输任何内容。\n\nAIONIO本质上还是同步，但是AIO可以实现异步。\nAIO真正实现了中断的功能，即注册一个监视资源的线程，然后OS可以去做其他事。当资源发起请求时，线程监视到这个变化，并通知OS来处理该资源的请求。\n\n总结\nAIO的做法是，每个水壶上装一个开关，当水开了以后会提醒对应的线程去处理。\nNIO的做法是，叫一个线程不停的循环观察每一个水壶，根据每个水壶当前的状态去处理。\nBIO的做法是，叫一个线程停留在一个水壶那，直到这个水壶烧开，才去处理下一个水壶。\n\n可以看出AIO是最聪明省力，NIO相对省力，BIO最愚蠢。\n","categories":["OS","概念","IO","OS"],"tags":["概念","OS"]},{"title":"Celery和AJAX配合实现异步刷新","url":"/2021/04/23/Celery%E5%92%8CAJAX%E9%85%8D%E5%90%88%E5%AE%9E%E7%8E%B0%E5%BC%82%E6%AD%A5%E5%88%B7%E6%96%B0/","content":"需求介绍由于 Celery 是异步队列，有时候用户的页面已经显示出来，但是后台仍在执行任务，我们想实现这样一个功能：当后台执行任务完成后，前端页面相应进行改变。\n这样的场景和需求非常常见，比如上传视频这个过程非常耗时，我们希望用户点击上传视频后，页面马上显示一个区域，表示某视频正在上传（比如视频的图片、标题、简介等马上显示出来），但是此时还不能点击观看（disable链接），只有当后台上传完毕后，才能在前端开放（enable链接）。\n在之前的Celery消息队列中已经介绍过 Celery，此处先简介 Ajax。\nAJAXAsynchronous JavaScript and XML。可以实现每次只使用HTTP请求一小部分资源并加载页面的某一些部分，而不用请求整个页面的所有资源并刷新整个页面所有内容。比较常见的 AJAX 使用场景就是在网页中“下拉显示更多”这样的操作。\n一般而言使用 AJAX 都需要搭配使用 jQuery，其常见的语法如下：\n$(document).ready(function()&#123;            $(&quot;.btn&quot;).click(function() &#123;        // 点击btn时会调用下面的函数                let id = $(&#x27;#id&#x27;).val();        // 获取id的值                $.ajax(&#123;                    url: &quot;&quot;,                    // 要发送请求的url，可以使用mako等模板                    type: &quot;GET&quot;,                // 请求的方式                    data: &#123;&#x27;id&#x27;: id&#125;,           // 一并发送的数据                        success: function(results)&#123; // 如果成功请求                        ...                    &#125;,                    error: function(error) &#123;    // 如果发生错误                        ...                    &#125;                &#125;);            &#125;);        &#125;);\n\n代码\n首先将操作放入 celery 异步队列中，得到一个 &lt;celery.result.AsyncResult&gt; 返回，最重要的是访问其中 id 属性，可以通过 id 访问最终队列的执行结果；\n&#x27;&#x27;&#x27;    function.py&#x27;&#x27;&#x27;class Func(View):    def get(req):        ...        task = celeryFunction.delay() # 得到一个&lt;celery.result.AsyncResult&gt;        ...        return render_to_redirect(req, self.TEMPLATE, data = &#123;&#x27;task_id&#x27;: task_id&#125;)  # 一定要将 task_id 保存住\n然后编写HTML页面用于直接显示内容，可以包含已处理的和待处理的，里面加上 ajax，而 ajax 中的 url 指向某个路由，用于访问执行结果并进行返回；\n$(document).ready(function()&#123;            $(&quot;.refresh&quot;).click(function() &#123;                let task_id = $(&#x27;#task_id&#x27;).val();                $.ajax(&#123;                    url: &quot;$&#123;reverse(&#x27;check&#x27;)&#125;&quot;,                    type: &quot;GET&quot;,                    data: &#123;&#x27;task_id&#x27;: task_id&#125;,                    success: function(results)&#123;                        // 根据最终返回的JSON内容改变本页面的内容                    &#125;,                &#125;);            &#125;);        &#125;);\n在 urls.py 中将上面 ajax 需要跳转的页面进行注册\nurlpatterns &#x3D; [    ...    path(&#39;check&#39;, views.check, name&#x3D;&quot;check&quot;),    ...]\n编写上述新加入的页面函数逻辑，并返回 JsonResponse 进入 ajax 的处理函数中（如 success 中，从而可以改变原有页面内容）\n&#x27;&#x27;&#x27;    views.py&#x27;&#x27;&#x27;from django.http import JsonResponsefrom celery.result import AsyncResultdef check(request):    task_id = request.GET.get(&#x27;task_id&#x27;)    if task_id:        task_res = AsyncResult(task_id)        return JsonResponse(&#123;&#x27;finish&#x27;: task_res.ready()&#125;)    return JsonResponse(&#123;&#x27;finish&#x27;: False&#125;)\n\n坑\n在返回给 ajax 信息时，一定要使用类似于 JSON 的格式，所以推荐使用 JsonResponse。\n\n如果你的 Celery 不幸给你返回了 HTTP 500，那么恭喜你，你应该是没有在 Celery 里设置 backend，也就是说你的服务器只负责帮你执行任务，但是不会把结果及相关信息存储到数据库。（别问我怎么知道的，现在正在东九五楼吹风呢）\n\n\n","categories":["Web","概念","前端"],"tags":["概念","web","celery"]},{"title":"HTTP和HTTPS","url":"/2021/04/26/HTTP%E5%92%8CHTTPS/","content":"HTTP超文本传输协议，是一个基于请求与响应，无状态的，应用层的协议，常基于TCP/IP协议传输数据，互联网上应用最为广泛的一种网络协议,所有的WWW文件都必须遵守这个标准。设计HTTP的初衷是为了提供一种发布和接收HTML页面的方法。\nHTTP主要有三个版本：HTTP1.0，HTTP1.1，HTTP2.0：\n\n在HTTP1.1中规定，一个TCP连接中可以传输多个HTTP请求，且支持了持久化连接，不会发送一个HTTP请求就断开\n在HTTP2.0中规定，一个TCP连接中可以将多个HTTP请求合在一起发送/接收，这是2.0的新特性\n\nHTTP的特点\n无状态：协议对客户端没有状态存储，对事物处理没有“记忆”能力，比如访问一个网站需要反复进行登录操作\n无连接：HTTP/1.1之前，由于无状态特点，每次请求需要通过TCP三次握手四次挥手，和服务器重新建立连接。比如某个客户机在短时间多次请求同一个资源，服务器并不能区别是否已经响应过用户的请求，所以每次需要重新响应请求，需要耗费不必要的时间和流量。\n基于请求和响应：基本的特性，由客户端发起请求，服务端响应\n简单快速、灵活\n通信使用明文、请求和响应不会对通信方进行确认、无法保护数据的完整性\n\n\nHTTPS可以视为加入了SSL的HTTP。HTTPS经由HTTP进行通信，利用SSL加密数据包。HTTPS使用的主要目的是提供对网站服务器的身份认证，同时保护交换数据的隐私与完整性。\n在加密的过程中，HTTPS使用了对称加密和非对称加密相结合的方法。\n对称加密 Vs 非对称加密对称加密即加密和解密的方法一致，比如客户端加密文件，用了一个密码123456(或者是通过了某个加密算法后)，那么服务端只要输入123456(或通过了客户端加密算法对应的解密算法后)即可以实现解密。\n非对称加密分为公钥和私钥，其中私钥是服务器独有，公钥是公开发送给客户端。公钥可以加密私钥，私钥也可以解密公钥，但是公钥无法解密公钥。\n中间人攻击在Client和Server通信的时候，理论上的流程如下：\n\nClient向Server发送请求，包括客户端浏览器支持的加密算法等信息\nServer发现是第一次请求，所以返回数据并附带自己保存的私钥0 对应的 公钥0\nClient收到 公钥0，之后每次发数据都用 公钥0 进行加密\nServer收到 公钥0 加密信息后使用 私钥0 解密即可\n\n但是在过程中，可能有中间人使坏，使流程变成如下：\n\nClient向Server发送请求，包括客户端浏览器支持的加密算法等信息\nServer发现是第一次请求，所以返回数据并附带自己保存的私钥0 对应的 公钥0\n中间人截获 公钥0，自己创建一个 私钥1，并发送 公钥1 给Client\nClient之后使用 公钥1 加密信息\n每次信息都被中间人截获，使用 私钥1 解码Client，然后把篡改的信息用 公钥0 加密发给Server\n\n\n\n\nHTTPS加密的过程CA证书证书是一种由大家公认的第三方机构颁发的一种证明，用于验证服务器是安全可靠的。一般公司需要向第三方机构提出申请，然后第三方机构验证合法性后进行颁发。\n比如网站www.lolol.com想要申请证书，第三方机构可能会要求我向服务器中放入一个指定的文件，或者是DNS重定向某个随机网页到www.lolol.com来证明我对服务器能够拥有权限。\n数字签名数字签名用于验证是否是某个私钥给我发送的信息。\n数字签名和加密解密过程类似，不过是反过来的：加密的是公钥，解密的是私钥；签名的是私钥，验证的是公钥。\n数字签名的特点：\n\n认证：确认给我发送签名的是拥有私钥的\n防抵赖：发送方一旦发送，不能反悔\n防篡改：数字签名的生成是和文件内容有关的，如果更改内容必然更改了数字签名，也就无法再解密\n\nHTTPS加密过程","categories":["Web","概念","概念","计算机网络"],"tags":["概念","web"]},{"title":"Celery消息队列","url":"/2021/04/22/Celery%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/","content":"什么是任务队列？任务队列就是一种类似“队列”(Queue)的数据结构，是一种用于线程或计算机之间分配工作的一种机制。可以理解为把多个任务按次序放入队列中，然后当有任务完成后就会被取出。\n什么是 Celery ？Celery是一种使用Python编写的任务队列，主要概念有：\n\n中间人（Broker）\n\n中间人（Broker）是一个消息传输的中间件。Celery通过消息机制进行通信，通常使用中间人（Broker）作为客户端和职程（Worker）调节。启动一个任务，客户端向消息队列发送一条消息，然后中间人（Broker）将消息传递给一个职程（Worker），最后由职程（Worker）进行执行中间人（Broker）分配的任务。\nCelery是没有Broker的，需要使用第三方方案。常用的有： RabbitMQ, Redis 和数据库。\n\nbackend\n\n通常程序发送的消息，发完就完了，可能都不知道对方时候接受了。为此，celery实现了一个backend，用于存储这些消息以及celery执行的一些消息和结果。一般而言，同样可以使用 Redis 或者 Django ORM 对这些结果进行存储和操作。\n\n\n\n安装 Celery本文不赘述，可以参考网上各种帖子，一般而言只需要执行以下的指令即可\npip install celery[&#x27;redis&#x27;]\n\n在 Django 中使用 Celery\n注意，在使用 Celery 前一定要启动 Redis 等服务器。\n\n配置非配置文件法app | |- tasks |    | |    |- task.py            &lt;- 用户创建，存放功能函数 |- config |    | |    |- settings.py        &lt;- Django 自带的 settings.py |    |- celeryConfig.py    &lt;- 用户创建，初始化 Celery\n\n&#x27;&#x27;&#x27;    celeryConfig.py&#x27;&#x27;&#x27;import celeryimport os# 参数0为固定设置，参数1为settings的路径os.environ.setdefault(&quot;DJANGO_SETTINGS_MODULE&quot;, &quot;config.settings&quot;)import djangodjango.setup()# main为当前模块的名称，broker设置中间人URL，backend设置存储URLapp = celery.Celery(main=&quot;videoweb&quot;, broker=&#x27;redis://localhost:6379/2&#x27;, backend=&#x27;redis://localhost:6379/3&#x27;)# 定义会使用 &#x27;app&#x27; 这个消息队列的文件的位置app.autodiscover_tasks([&#x27;app.tasks&#x27;])\n\n&#x27;&#x27;&#x27;    task.py&#x27;&#x27;&#x27;from app.config.celeryConfig import appimport time@app.taskdef func():    # 一些需要放在异步队列中运行的，比较耗时/会造成阻塞的任务代码\n\n配置文件法app | |- tasks |    | |    |- task.py            &lt;- 用户创建，存放功能函数 |- config |    | |    |- settings.py        &lt;- Django 自带的 settings.py |- celery |    | |    |- celeryConfig.py    &lt;- 用户创建，设置信息 |    |- celeryApp.py       &lt;- 用户创建，初始化 celery\n\n\n注意， celery 相关的设置和初始化需要放在同一个文件夹下\n\n&#x27;&#x27;&#x27;    celeryConfig.py&#x27;&#x27;&#x27;BROKER_URL = &#x27;redis://127.0.0.1:6379&#x27;               # 指定 BrokerCELERY_RESULT_BACKEND = &#x27;redis://127.0.0.1:6379/0&#x27;  # 指定 Backend                        CELERY_IMPORTS = (                                  # 指定导入的任务模块    &#x27;app.tasks.task&#x27;)\n\n&#x27;&#x27;&#x27;    celeryApp.py&#x27;&#x27;&#x27;from celery import Celeryapp = Celery(&#x27;videoweb&#x27;)app.config_from_object(&#x27;celeryConfig&#x27;)   # 加载配置\n\n&#x27;&#x27;&#x27;    task.py&#x27;&#x27;&#x27;from app.celery.celeryApp import app@app.taskdef func():    # 一些需要放在异步队列中运行的，比较耗时/会造成阻塞的任务代码\n\n使用在配置完成后，需要手动启动 celery 服务\n# 代表将使用videoweb注册的app放入异步队列，使用4个workercelery -A videoweb worker -c 4 -l info  \n\n在其他文件中需要调用func()时，可以使用func.delay()的格式，即可将func()函数放到异步队列中运行。\n\n注意，在使用.delay(params)的时候，params只能是可解析格式，如list, str, int, json等，不能是类似于Queryset之类的内容。\n\n查看执行的结果由于是异步进程，执行的结果可能不会在编写的代码中体现，所以需要在后续重新读取执行的结果并对页面等进行相应的改动。\n实现该过程的方法就是使用 AJAX。这并不在本文的讨论范围内，本文主要告知如何访问消息队列中的程序。\n在使用func.delay()时，会返回一个 AsyncResult 实例，其有一些属性和方法，如 id, successful() 和 *failed()*。一般而言，我们会将 id 一并传入 Django 的 Template 视图中，然后编写 AJAX，读取 id 对应线程的执行结果，并根据是否成功处理页面。\n&#x27;&#x27;&#x27;    views.py&#x27;&#x27;&#x27;def get(req):    ...    task = func.delay(params)    id = task.id    data[&#x27;id&#x27;] = id        ...    return render_to_redirect(req, self.TEMPLATE, data=data)\n\n详细的使用 Celery + AJAX 的操作我也不会日后探究 /斜眼笑。\n","categories":["Web","概念"],"tags":["web","celery"]},{"title":"Django中Cookie和Session实现登录/注销","url":"/2021/04/25/Django%E4%B8%ADCookie%E5%92%8CSession%E5%AE%9E%E7%8E%B0%E7%99%BB%E5%BD%95-%E6%B3%A8%E9%94%80/","content":"什么是 cookies &amp; session?会话（Session）跟踪是Web程序中常用的技术，用来跟踪用户的整个会话。常用的会话跟踪技术是Cookie与Session。Cookie通过在客户端记录信息确定用户身份，Session通过在服务器记录信息确定用户身份\ncookies在程序中，会话跟踪是很重要的事情。理论上，一个用户的所有请求操作都应该属于同一个会话，而另一个用户的所有请求操作则应该属于另一个会话，二者不能混淆。\n而Web应用程序是使用HTTP协议传输数据的。HTTP协议是无状态的协议。一旦数据交换完毕，客户端与服务器端的连接就会关闭，再次交换数据需要建立新的连接。这就意味着服务器无法从连接上跟踪会话。\nCookie就是这样的一种机制。它可以弥补HTTP协议无状态的不足。即每次HTTP协议只需要访问到同一个Cookie则认为请求和相应是同一个对象接收和发出。\nsession客户端浏览器访问服务器的时候，服务器把客户端信息以某种形式记录在服务器上。这就是Session。客户端浏览器再次访问时只需要从该Session中查找该客户的状态就可以了。\n\n比较常见的就是登陆。如果用户在客户端通过登陆验证，那么就会设置一个session来标记某个用户已经登录，访问别的网页时可以通过 middleware 访问session来查看某个用户是否已经登录/登录是否过期。\n\n两者的比较一个存储在客户端，一个存储在服务端。如果把访问的过程看做一个人参观某个公司，那么：\n\n如果不使用cookie和session，那么他每次进出都需要找保安报备\ncookies相当于给这个人配一个临时卡(身份识别保存在客户端)，他刷卡就可以进入公司，参观结束后(cookies生命周期结束后)则回收卡(消除各种数据)\nsession相当于公司的门禁处设置人脸识别(身份识别在服务端)，他通过验证即可，参观结束后消除人脸识别机器的相关信息(服务器进行flush)\n\n在Django实现cookies和session登录/注销Cookies 版本验证是否登录的装饰器&#x27;&#x27;&#x27;    permission.py&#x27;&#x27;&#x27;def checkLoginByCookies(func):    @functools.wrap(func)    def wrapper(self, request, *args, **kwargs):        # COOKIES_NAME是保存cookies的key名字        # 可以自定义，只要保证在设置cookies的时候也是用了这个名字即可        id = request.COOKIES.get(COOKIES_NAME)                # 如果没有cookies信息，则保存当前路径，并跳转到登录界面        # 这样在登录后可以直接跳回当前路径        if not id:            return redirect(&#x27;&#123;&#125;?to=&#123;&#125;&#x27;.format(reverse(&#x27;DESTINATION&#x27;), request.path))          # 如果这样定义，则说明设置cookies的时候保存的为&#123;COOKIES_NAME: user.id&#125;        user = User.objects.filter(pk=id)        if not user:            return redirect(&#x27;&#123;&#125;?to=&#123;&#125;&#x27;.format(reverse(&#x27;DESTINATION&#x27;), request.path))            # 如果一切正常，则执行封装的函数        return func(self, request, *args, **kwargs)              return wrapper\n\n登录界面class Login(View):    TEMPLATE = &#x27;login.html&#x27;    def get(self, req):        id = req.COOKIES.get(COOKIES_NAME)        # 如果在已经登录的情况下访问login界面，则自动跳回主页        if id:            return redirect(reverse(&#x27;HOMEPAGE&#x27;))        # 如果还未登录，则需要登录，登录完成后跳回当前的路径        to = req.GET.get(&#x27;to&#x27;, &#x27;&#x27;)        return render_to_response(req, self.TEMPLATE, &#123;&#x27;to&#x27;: to&#125;)    &#x27;&#x27;&#x27;        此函数中调用了JsonResponse是用于AJAX显示错误提示    &#x27;&#x27;&#x27;    def post(self, req):        username = req.POST.get(&#x27;username&#x27;)        password = req.POST.get(&#x27;password&#x27;)        # 查看是否存在用户        exists = User.objects.filter(username=username).exists()        if not exists:            return JsonResponse(&#123;&#x27;status&#x27;: -1, &#x27;error&#x27;: &#x27;该用户不存在&#x27;&#125;)        # 查看用户账号密码是否匹配        user = authenticate(username=username, password=password)        if not user:            return JsonResponse(&#123;&#x27;status&#x27;: -1, &#x27;error&#x27;: &quot;登录失败&quot;&#125;)        user = User.objects.get(username=username)        if user.is_staff is False:            return JsonResponse(&#123;&#x27;status&#x27;: -1, &#x27;error&#x27;: &quot;缺少权限，请联系管理员&quot;&#125;)        current_time = datetime.datetime.utcnow()                   # 获取当前时间        expire_time = current_time + datetime.timedelta(minutes=5)  # 推迟五分钟作为过期时间        # 配置cookie        response = JsonResponse(&#123;&#x27;status&#x27;: 0, &#x27;error&#x27;: &#x27;&#x27;&#125;)        response.set_cookie(COOKIES_NAME, str(user.id), expires=expire_time)        return response\n\n注销class Logout(View):    def get(self, req):        response = redirect(reverse(&#x27;LOGIN&#x27;))        response.delete_cookie(COOKIES_NAME)  # cookies版本        return response\n\nSession 版本验证是否登录的装饰器def checkLoginBySession(func):    @functools.wraps(func)    def wrapper(self, request, *args, **kwargs):        # is_login和SESSION_NAME都是用户自定义key名字        status = request.session.get(&#x27;is_login&#x27;)        id = request.session.get(SESSION_NAME)        # 如果状态为未登录        if status != &#x27;true&#x27;:            return redirect(&#x27;&#123;&#125;?to=&#123;&#125;&#x27;.format(reverse(&#x27;LOGIN&#x27;), request.path))        user = User.objects.filter(pk=id).exists()        if user:            return func(self, request, *args, **kwargs)        else:            return redirect(&#x27;&#123;&#125;?to=&#123;&#125;&#x27;.format(reverse(&#x27;LOGIN&#x27;), request.path))    return wrapper\n\n\n登录class Login(View):    TEMPLATE = &#x27;/login.html&#x27;    def get(self, req):        id = req.session.get(SESSION_NAME)        if id:            return redirect(reverse(&#x27;HOMEPAGE&#x27;))        to = req.GET.get(&#x27;to&#x27;, &#x27;&#x27;)        return render_to_response(req, self.TEMPLATE, &#123;&#x27;to&#x27;: to&#125;)    def post(self, req):        username = req.POST.get(&#x27;username&#x27;)        password = req.POST.get(&#x27;password&#x27;)        # 查看是否存在用户        exists = User.objects.filter(username=username).exists()        if not exists:            return JsonResponse(&#123;&#x27;status&#x27;: -1, &#x27;error&#x27;: &#x27;该用户不存在&#x27;&#125;)        # 查看用户账号密码是否匹配        user = authenticate(username=username, password=password)        if not user:            return JsonResponse(&#123;&#x27;status&#x27;: -1, &#x27;error&#x27;: &quot;登录失败&quot;&#125;)        user = User.objects.get(username=username)        if user.is_staff is False:            return JsonResponse(&#123;&#x27;status&#x27;: -1, &#x27;error&#x27;: &quot;缺少权限，请联系管理员&quot;&#125;)        # 配置session        req.session[SESSION_NAME] = user.id        req.session[&#x27;user_name&#x27;] = user.username        req.session[&quot;is_login&quot;] = &quot;true&quot;        req.session.set_expiry(300)         # 300s后失效        response = JsonResponse(&#123;&#x27;status&#x27;: 0, &#x27;error&#x27;: &#x27;&#x27;&#125;)        return response\n\n注销class Logout(View):    def get(self, req):        response = redirect(reverse(&#x27;LOGIN&#x27;))        req.session.flush() # session版本        return response","categories":["Web","Python","概念","Django","Django"],"tags":["概念","web","Django"]},{"title":"How to write 'hello world' in HEXO (I)","url":"/2021/04/18/How-to-write-hello-world-in-HEXO-I/","content":"What is HEXO?HEXO is a very famous and useful web framework. People always combine HEXO with GitHub to bulid their own blogs or webpages.\nInstallFirst of all, you need to install node.js, you can refer to its website here, and git, you can refer here.\nAfter configuration, you are supposed to install HEXO via node.js command called npm.\nnpm install -g hexo-cli\n\nInitializeOnce HEXO is installed, run the following commands to initialize HEXO in the target &lt;folder&gt;.\nhexo init &lt;folder&gt;  # initcd &lt;folder&gt;npm install         # install other dependency\n\nOnce initialized, here’s what your project folder will look like:\n.├── _config.yml         # user can config settings here├── package.json        # record dependency etc.├── scaffolds           # define three post methods -- post, draft and page├── source              # store your posts and other resources|   ├── _drafts|   └── _posts└── themes              # user&#39;s custom themes\n\nConfigurationIn _config.yml file, you can stylize your own settings. For example:\n\ntitle – your website’s name\nurl – the URL of your website\n\nyou can find more details here.\nCommandnewhexo new [layout] [-p/--path filePath] &lt;title&gt;\n\nCreates a new article. If no [layout] is provided, Hexo will use the default_layout from _config.yml. \nBy default, Hexo will use the title to define the path of the file. For page, it will create a directory of that name and an index.md file in it. Use the –path option to override that behaviour and define the file path:\nhexo new page --path about/me &quot;About&quot;\nwill create source/about/me.md file with the title “About” set in the front matter.\nFor post, it will automatically generate a new file in source/_posts/&lt;title&gt;.md\nserverhexo serverhexo s\nRun a local server.\ngeneratehexo g\nGenerate static files, which means it will convert/render .md or .ejs files to html files.\ncleanhexo clean\n\nCleans the cache file (db.json) and generated files (public).\ndeployhexo d\n\nDeploy your files to remote server. You can set your deploy destination:\n\nopen _config.yml\nconfigure depoly area, for example, if you want to deploy your website in GitHubdeploy:    type: git    repository: https://github.com/xxx/xxx.github.io.git    branch: master\n\n","categories":["Web","HEXO"],"tags":["web","hexo"]},{"title":"How-to-write-hello-world-in-HEXO-II","url":"/2021/04/19/How-to-write-hello-world-in-HEXO-II/","content":"Post your fileNow, you can begin to write your markdown or ejs files. When you want to post a file, you can just run codes in orders.\n\nhexo new post &lt;fileName&gt;\nwrite something\nhexo clean\nhexo g\nhexo d\n\nFront-matterWhen you new a file, HEXO will automatically generate a file in certain format, it depends on your METHOD (like post, draft and page) in scaffolds.\nFor POST METHOD, it will generate a file with beginning below:\n---title: &lt;fileName&gt;date: &lt;createTime&gt;---\n\nIn HEXO, the beginning area which surrounded by --- is HEXO’s syntax. title represents the file’s title, and data represents the create time. \nFor instance, when we use below Front-matter, we can get corresponding webpage.\n---title: HELLOdate: 2021-04-19---&lt;main&gt;\n\n&lt;h1&gt;HELLO&lt;&#x2F;h1&gt;[Username] &lt;span&gt;2021-04-19&lt;&#x2F;span&gt; &lt;main&gt;\n\n\ncategories &amp; tagsExcept title and date, there are many other key words:\n\ncategories – indicates the categories it belongs to\ntags – indicates the tags it has\n\nNotice: categories is different with tags. tags is unordered, while categories is ordered.\n---title: date:categories:- Web- HEXOtags:- web- hexo---\n\nThis file will be attached tags with “web” and “hexo”, these tags are parallel. However, it also will be archived to Web and HEXO, and Web is father category, HEXO is child category.\n\n\nIf you want to assign many father-child categories, you can use []\ncategories:- [Web, HEXO]- [Web, Framework]\n","categories":["Web","HEXO"],"tags":["web","hexo"]},{"title":"Java转型","url":"/2021/06/22/Java%E8%BD%AC%E5%9E%8B/","content":"转型转型一般分为两种情况：\n\n向上转型：子类 &rarr; 父类（可以是类/接口），Father f = new Son()\n向下转型：父类 &rarr; 子类，Son s = (Son) f \n\n如何判断能否转型？只要右边的能当做左边的使用就是正确的，或者说只要左边有的功能右边都有就是正确的。比如手机 = 苹果手机，苹果手机能当成普通手机使用，那么这样的转换就是合理的。\n向上转型public class test &#123;    public static void main(String[] args) &#123;        Human h = new Male();        h.sleep();                      // Male sleep..        System.out.println(h.name);     // Human        h.father();                     // This is father    &#125;&#125;class Human&#123;    String name = &quot;Human&quot;;    public void sleep()&#123;        System.out.println(&quot;Human sleep..&quot;);    &#125;    public void father()&#123;        System.out.println(&quot;This is father&quot;);    &#125;&#125;class Male extends Human&#123;    String name = &quot;Male&quot;;    @Override    public void sleep() &#123;        System.out.println(&quot;Male sleep..&quot;);    &#125;    public void son()&#123;        System.out.println(&quot;This is son&quot;);    &#125;&#125;\n\n在向上转型时：\n\n父类的引用所指向的属性是父类的属性。\n如果子类重写了父类的方法，那么父类引用调用的方法是子类的方法,这个叫动态绑定。如果子类没有重写父类方法，那么调用的还是父类方法。\n不能调用子类独有的方法。\n\n\n如果非要调用子类的属性，那么需要在父类定义一个属性getter，然后在子类中进行重写\n\n向下转型只有向上转型的引用才能安全的使用向下转型，如果父类引用指向父类本身，那么使用向下转型可能会出错。\npublic class test &#123;    public static void main(String[] args) &#123;        Human h = new Male();        Male m = (Male) h;      // 向下转型        System.out.println(m.name); // Male        m.sleep();                  // Male sleep..        m.son();                    // This is son        m.father();                 // This is father    &#125;&#125;class Human&#123;    String name = &quot;Human&quot;;    public void sleep()&#123;        System.out.println(&quot;Human sleep..&quot;);    &#125;    public void father()&#123;        System.out.println(&quot;This is father&quot;);    &#125;&#125;class Male extends Human&#123;    String name = &quot;Male&quot;;    @Override    public void sleep() &#123;        System.out.println(&quot;Male sleep..&quot;);    &#125;    public void son()&#123;        System.out.println(&quot;This is son&quot;);    &#125;&#125;\n\n总结向上转型会丢失子类特有的方法，但是仍然能保持子类中重写的方法；为了获取子类特有的方法，可以在向上转型基础上增加向下转型即可。\n","categories":["Java","概念"],"tags":["概念","Java"]},{"title":"Python4Redis","url":"/2021/05/12/Python4Redis/","content":"本文主要介绍基于Python来连接、操作Redis数据库。在Python中，使用redispy库来进行连接。关于redispy详细的文档可以参考GitHub。\n连接Redisimport redis# 简历连接实例，参数为&quot;主机&quot;，&quot;端口&quot;，&quot;数据库id&quot;r = redis.Redis(host=&#x27;localhost&#x27;, port=6379, db=0, decode_responses=True)\n\n在Python3中返回的是bytes类型，想要直接获取str类型，需要设置decode_responses=True\n\n注意，在redispy中是没有设置SELECT操作更换数据库id，所以请为每个数据库都创建独立的连接实例。\n在默认情况下，redispy会自动给每个连接实例创建对应的连接池，但是用户也可以手动将连接池实例放入已存在的连接池中。\npool = redis.ConnectionPool(host=&#x27;localhost&#x27;, port=6379, db=0)r = redis.Redis(connection_pool=pool)\n\n\nPipleline在Redis中为了节省RTT，会使用pipeline将多个指令一并发送。在python中的操作如下：\npipe = r.pipeline()pipe.operation0()pipe.operation1()...pipe.operationN()pipe.execute()\n\n由于pipeline是放入缓冲区顺序执行的，也可以在代码中串联起来\npipe.operation0().operation1(). ... .operationN().execute()\n\n在redispy中，上述pipeline过程会自动被转换成“事务”，以保证原子性。如果不希望自动被转换成“事务”，则需要设置pipe = r.pipeline(transaction=False)。\n\nTransaction在redispy中，可以使用pipeline实现transaction\npipe = r.pipeline()while True:    try:        pipe.watch(&#x27;&lt;key&gt;&#x27;) # 加锁        pipe.multi()        # 组队            ...        pipe.execute()      # 执行        break    except WatchError:        continue    finally:        pipe.reset()        # 归还到连接池，默认情况下会自动调用\n\n存在一种更便捷的方法，用于处理try-catch和加锁等操作。它需要一个回调函数，一个管道对象和任意数量的键都将被监视\ndef transactionFunc(pipe):    pipe.multi()    ...    pipe.execute()# 传入回调函数和需要被加锁监视的keyr.trascation(transactionFunc, &lt;watched_key&gt;)\n\n\n数据类型对于基本的Redis操作都有支持。\n\n对于最普通的，传入参数都是func(key: str, val: str/list/tuple)\n对于多个设置，如mset等，传入的都是键值对的mapping\n对于设置时间相关的，如setex等，func(key: str, time: int, value: str)\n对于有范围的，如lrange等，传入的都是func(key: str, start: int, end: int)\n对于有个数的，如lrem等，传入的参数func(key: str, num: int, value: str)\n对于有间隔的，如incrby等，传入的参数func(key: str, step: int)\n\n\n注意，对于list/tuple等，传入时参数要为*args；对于dict，传入时参数要为**kwargs\nvalues = [&#x27;bob&#x27;, &#x27;jack&#x27;]r.lpush(&#x27;user&#x27;, *values)\n\n\nPubSub订阅订阅非常简单，只需要输入以下的指令创建pubsub实例，然后订阅指定的频道即可，其中psubscribe可以匹配正则表达式。\nr = redis.Redis(...)p = r.pubsub()p.subscribe(&#x27;channel0&#x27;, &#x27;channel1&#x27;, ...)p.psubscribe(&#x27;channel*&#x27;)    # 订阅任何channel开头的频道\n\n通过get_message可以获得实例对应的信息。其中消息体的具体含义：\n\ntype – subscribe, unsubscribe, psubscribe, punsubscribe, message, pmessage中的某一个\nchannel – 订阅的频道或者是有新消息的频道\npattern – 与已发布消息的频道匹配的模式。 除pmessage类型外，在所有情况下均为None\ndata – 消息信息。如果是有消息，则为消息内容，否则为频道id\n\n&gt;&gt;&gt; p.get_message()&#123;&#x27;pattern&#x27;: None, &#x27;type&#x27;: &#x27;subscribe&#x27;, &#x27;channel&#x27;: b&#x27;channel1&#x27;, &#x27;data&#x27;: 1&#125;&gt;&gt;&gt; p.get_message()&#123;&#x27;pattern&#x27;: None, &#x27;type&#x27;: &#x27;subscribe&#x27;, &#x27;channel&#x27;: b&#x27;channel0&#x27;, &#x27;data&#x27;: 2&#125;&gt;&gt;&gt; p.get_message()&#123;&#x27;pattern&#x27;: None, &#x27;type&#x27;: &#x27;psubscribe&#x27;, &#x27;channel&#x27;: b&#x27;channel*&#x27;, &#x27;data&#x27;: 3&#125;\n\n发布使用p.publish进行消息发布，可以指定发布的位置和消息内容。\n# the publish method returns the number matching channel and pattern# subscriptions. &#39;my-first-channel&#39; matches both the &#39;my-first-channel&#39;# subscription and the &#39;my-*&#39; pattern subscription, so this message will# be delivered to 2 channels&#x2F;patterns&gt;&gt;&gt; r.publish(&#39;my-first-channel&#39;, &#39;some data&#39;)2&gt;&gt;&gt; p.get_message()&#123;&#39;channel&#39;: b&#39;my-first-channel&#39;, &#39;data&#39;: b&#39;some data&#39;, &#39;pattern&#39;: None, &#39;type&#39;: &#39;message&#39;&#125;&gt;&gt;&gt; p.get_message()&#123;&#39;channel&#39;: b&#39;my-first-channel&#39;, &#39;data&#39;: b&#39;some data&#39;, &#39;pattern&#39;: b&#39;my-*&#39;, &#39;type&#39;: &#39;pmessage&#39;&#125;\n\n取消订阅对于subscribe，使用unsubscribe；对于psubscribe，使用punsubscribe。其可以指定取消订阅的频道名字/模式串，如果不传入任何参数则视为对所有频道取消订阅。\np.unsubscribe()p.punsubscribe(&#x27;channel*&#x27;)\n\n通过回调函数redis-py支持使用回调函数实现pubsub。回调函数要传入一个message变量，该变量为dict类型，就类似于之前的get_message返回的dict。如果想要订阅一个频道，则需要传入一个dict，其key为channelName，value为回调函数。\n当一个信息被读取后，handler会自动帮我们在message这个dict中保存信息，并调用回调函数，所以get_message返回的都是None而非信息。\ndef messageHandler(message):    print(message)p.subcribe(**&#123;&#x27;mychannel&#x27;: messageHandler&#125;) # 订阅mychannelp.publish(&#x27;mychannel&#x27;, &#x27;hello redis&#x27;)   # 此时message中有&#123;data: &#x27;hello redis&#x27;&#125;msg = p.get_message(&#x27;mychannel&#x27;)    # 打印message，但是返回给msg的为Noneprint(msg)  # None\n\n只接收新消息通过设置p = r.pubsub(ignore_subscribe_messages=True)，这样在p.get_message()时，如果没有新消息，则不会返回任何值；如果有信息消息，才会返回值。\n读取消息轮询get_message内部的实现机制是快速的调用select，在多个数据库之间遍历，寻找是否有新的消息，如果有则获取，否则返回None。\nwhile True:    message = p.get_message()    if message:        ...        time.sleep(0.001)  # be nice to the system :)\n\n监听listen()是一个生成器，其会阻塞其他进程直到有消息。\nfor message in p.listen():    ...\n\n另起线程可以将事件的循环放入另一个独立的线程中。run_in_thread()可以创建一个独立的线程，并在该线程内部开启一个循环，不断使用第一种方法查看是否有可用的信息。\n注意：要使用该方法，必须使用回调函数。\np.subscribe(**&#123;&#x27;my-channel&#x27;: my_handler&#125;)thread = p.run_in_thread(sleep_time=0.001)# the event loop is now running in the background processing messages# when it&#x27;s time to shut it down...thread.stop()\n\n\n使用Lua脚本redis-py支持 EVAL, EVALSHA, 和 SCRIPT 这些操作，但是为了让代码更具有Python的风格，同时省去一些不必要的麻烦，我们可以使用独有的方法来加载并执行Lua脚本。\nlua_script = r.register_script(lua) # 传入lua代码，返回脚本实例lua_script(keys=[...], args=[...])  # 执行脚本，其中keys传入参数作为LUA中的KEYS，args作为ARGV\n\n在执行lua_script时，还可以设置client，用于表明脚本在哪个平台上运行。如果不指明，则默认为注册lua_script的平台。\n","categories":["Redis"],"tags":["redis"]},{"title":"Python中的浅拷贝与深拷贝","url":"/2021/05/20/Python%E4%B8%AD%E7%9A%84%E6%B5%85%E6%8B%B7%E8%B4%9D%E4%B8%8E%E6%B7%B1%E6%8B%B7%E8%B4%9D/","content":"可变对象 VS 不可变对象在Python中，诸如int, string, tuple等称为不可变对象，主要是因为他们不能直接对数据进行修改，比如string中不能直接更改某一个位置的字符，tuple不能直接更改某一个内容。\na = &quot;hello&quot;# 不能直接改变内容，如操作 a[1] = &#x27;w&#x27; 是不允许的print(id(a))    # 1008a = &quot;world&quot;     # 这样的操作意味着内存中新建一个&quot;world&quot;，地址与&quot;hello&quot;不同，然后让a这个引用指向新的内存地址print(id(a))    # 1010\n\na = 1print(id(a))    # 1008a += 1          # 相当于计算出结果为2，然后内存中新建2，地址与1不同，然后a引用指向新的地址print(id(a))    # 1010\n\n诸如list, dict, set等称为可变对象，主要是他们可以直接对数据进行修改，如list可以通过索引访问并修改内容。\na = [1,2,3]print(id(a))    # 1008a.pop()print(id(a))    # 1008，即内存位置没有改变\n\n\nis VS ==a == b是用于判断数值是否相等；a is b是用于判断在内存中是否存储在同一个位置，即是否为同一个对象，也就是id(a) == id(b)\n\n引用由于Python的逻辑是“万物皆对象”，所以每个变量名都是一个引用。具体而言，比如定义a = 1，那么在内存中有一个int 1，然后a作为引用指向该地址。同理，定义b = [1,2,3]，那么内存中有一片区域[1,2,3]，然后b作为引用指向该地址。\n不可变对象对于不可变对象而言，同样的内容在内存中只会存储一个。\n由于相同内容内存中只有一个，所以不存在拷贝的问题。\n\n拷贝：内容一样，但是存储的地点不同。\n\na = 1aa = aprint(aa is a)  # True，因为`1`只在内存中存储了一个，aa和a都是指向内存同一个地方aa = 2          # 相当于在内存中新建一个`2`，然后设置一个引用名为aa，指向该内存地址print(a, aa, aa is a)   # 1, 2, False\n\na = 1   # 1008 -&gt; 1b = 2   # 1010 -&gt; 2a += 1  # 此时结果为2，由于内存中已经有了2，所以直接新建一个引用a，指向已有的内存地址1010print(a is b)   # True\n\n可变对象对于可变对象而言，同样的内容可能存储在不同的内存区域。因此，只有可变对象才需要讨论浅拷贝和深拷贝。\na = [1,2,3] # 1008b = [1,2,3] # 1010print(a is b)   # False，因为a和b虽然内容一样，但是指向两个不同的对象，这两个对象在内存的地址也不同\n\n\n引用 VS 浅拷贝 VS 深拷贝import copya = [1,2]b = [3,4]c = [a,b, 100]d = c                   # 引用e = copy.copy(c)        # 浅拷贝f = copy.deepcopy(c)    # 深拷贝\n\n\n引用引用就是直接赋值，相当于只是起了一个别名，指向的位置没有任何变化，原数据的任何变动都会影响该引用。\n浅拷贝使用copy.copy()或者是[:]都是浅拷贝，意思就是直接拷贝原引用的指向，并不拷贝指向的内容。\n深拷贝使用copy.deepcopy()，意思就是拷贝指向和指向的内容，新建一个完全独立的内容，不会受任何影响。\n对于不可变元素内包含可变元素时对于不可变元素，如果内部存储的仍然是不可变元素，那么就不存在拷贝的概念。\n如果不可变元素内存储了任意一个可变元素，那么copy和引用是一样的，但是deepcopy仍然会执行。\na = [1,2]b = [3,4]c = (a, b)    # 引用和copy地址一样，deepcopy会创建独立的d = (1, 2)    # 引用、copy和deepcopy地址一样，无差别","categories":["Python","概念"],"tags":["概念","python"]},{"title":"Python中的特殊成员与魔法方法","url":"/2021/05/20/Python%E4%B8%AD%E7%9A%84%E7%89%B9%E6%AE%8A%E6%88%90%E5%91%98%E4%B8%8E%E9%AD%94%E6%B3%95%E6%96%B9%E6%B3%95/","content":"特殊成员和魔法方法是一系列特定结构的成员/方法，其格式为__XXX__，使用这些成员和方法通常会有比较奇特的效果，比如说 使用某个函数时就会自动调用某个方法，想要查看隐藏的信息就要访问特殊的成员 等。\n特殊成员__class__用于查看类名\nclass MyClass:    ...myclass = MyClass()print(myclass.__class__)    # __main__.MyClass\n\n__module__用于查看类的来源\nfrom other.modules import MyClassmyclass = MyClass()print(myclass.__module__)    # other.modules\n\n__dict__用于查看属性\nclass MyClass:    def __init__(self, name, age):        self.name = name        self.age = agemyclass = MyClass(&#x27;tom&#x27;, 18)print(myclass.__dict__) # &#123;name: &#x27;tom&#x27;, age: 18&#125;\n\n__str__定义打印输出时的显示内容\nclass MyClass:    def __str__(self):        return &quot;hello world&quot;myclass = MyClass()print(myclass)  # hello worldsentence = &quot;I want to say: %s&quot; % myclassprint(sentence) # I want to say: hello world\n\n\n魔法方法__new__(cls, ...) 和 __init__(self, ...)注意，__new__(cls, ...)为构造函数，用于创建类对象，而__init__(self, ...)仅仅是初始化函数，用于将预设的内容传递到新建的类内。这两个函数在使用诸如myClass = MyClass()时自动调用。\n__call__(self, *args, **kwargs)使得类和函数一样，可以直接加上()并传入参数调用。\nclass Add:    def __call__(self, *args):        return sum(args)myadd = Add()myadd(1,2,3)    # 6\n\n__getitem__(self, key) 和 __setitem__(self, key, value)使得对象可以使用[]进行获取和设置，就类似于字典一样。\nmyclass[key]            # 调用__getitem__(self, key)myclass[key] = value    # 调用__setitem(self, key, value)\n\n__getslice__(self, begin, end) 和 __setslice__(self, begin, end, value)使得对象可以使用[begin: end]这样类似list的方式进行获取和设置。\n__iter__(self)通过在函数内返回迭代器，使得对象可以被循环。\n__add__(self, other)实现加法操作。对于其他运算也有相应的魔法方法\n__lt__(self, other)x&lt;y相当于调用x.lt(y)，定义了使用&lt;时的评判标准。对于其他比较运算，也有对应的魔法方法。\n","categories":["Python","概念"],"tags":["概念","python"]},{"title":"Python全局解释器锁GIL","url":"/2021/05/20/Python%E5%85%A8%E5%B1%80%E8%A7%A3%E9%87%8A%E5%99%A8%E9%94%81GIL/","content":"GIL全局解释器锁GIL和Python其实并没有多大关系。因为Python是解释型语言，所以需要解释器，那么在最常见的C语言编写的CPython中，有一个部件会限制多线程的性能，这个部件就是GIL。\n在CPython运行的Python中，多线程实际上是不存在的，比如CPU有两个核，py文件中开了两个线程，那么实际上CPU的2个核利用率都为50%，即两个核实际上是交替运行线程的，即串行执行任务而非并行。这么做的原因就是因为GIL限制了每一次一个进程只能执行一个线程。\n因此，在Python中想要实现真正的并行，需要使用多进程而非多线程。\n","categories":["Python","概念"],"tags":["概念","python"]},{"title":"Python方法解析顺序表MRO","url":"/2021/05/21/Python%E6%96%B9%E6%B3%95%E8%A7%A3%E6%9E%90%E9%A1%BA%E5%BA%8F%E8%A1%A8MRO/","content":"MRO主要是解决多继承中重复继承的问题。\n在使用父类名.__init__()的方法中，会造成多次继承父类的父类，如下图所示。\n\n为了避免这样的问题，可以使用super，该方法基于MRO，根据MRO的顺序决定继承的顺序。\n\n使用className.__mro__可以查看MRO链，使用super().__init__()方法时会在MRO链中选中当前class，然后调用下一个class的__init__方法。\n也可以使用super(class, self).__init__()指定调用的下一个class的__init__方法。\n","categories":["Python","概念"],"tags":["概念","python"]},{"title":"Redis基础","url":"/2021/05/17/Redis%E5%9F%BA%E7%A1%80/","content":"NoSQL 数据库NoSQL (No only SQL)是一个高性能的 key-value 非关系型数据库。\nRedis 优势Redis 有众多优势：\n\n性能好：可以用于减小CPU压力和数据库的读写压力\n数据类型丰富\n原子性：即单个操作是原子性的，要么成功要么完全不执行；多个操作可以使用事务完成原子性操作\n注：Redis 支持事务，但是和 MySQL 的事务不同，并不支持ACID特性。\n\n\n持久化数据库：运行在内存，但是可以将数据持久化到磁盘\n\nRedis 主要适用于“高并发、大数据、可扩展”的情形，但是不适用于“需要大量事务操作和结构化查询”的任务中。\nredis VS memcacheRedis 和常用的 memcache 有很大的不同：\n\nmemcache 不能持久化，只能将数据保存在内存中，断电后数据消失\nmemcache 没有数据类型概念，存的是json\nmemcache 使用 “串行+多线程+锁” 的方式实现并发，而 redis 使用 “单线程+多路IO复用” 实现并发\n\n\n为什么细分类型比使用Json好？\n\n如果使用json想要取回某一条数据时，需要返回整个Json，IO的带宽和网络带宽代价高\n计算向数据转移：使用json时获取数据需要在client编写代码解析整个json数据进行解读；而细分数据类型时计算在server端完成，client直接得到计算完的结果\n\n\n为什么 redis 支持高并发并效率高\nredis 基于内存，免去了磁盘读写，减小了DB的IO压力\nredis 单线程，不受CPU的限制，也省去了上下文切换\nredis 多路复用，可以处理并发请求 (使用了epoll)\n\n\nRedis 数据类型和基本操作数据库设置Redis 默认有16个库\n\nselect &lt;dbid&gt;来进行数据库切换\nkeys *查看所有的keys\nexists &lt;key&gt;查看某个key是否存在\ndel &lt;key&gt;删除某个key\nunlink &lt;key&gt;异步删除某个key\ntype &lt;key&gt;查看key对应数据的数据类型\nobject encoding &lt;key&gt;查看key对应数据的编码方式/实现方式\nexpire &lt;key&gt; &lt;time&gt;设置某个key的生命周期\nttl &lt;key&gt;查看当前剩余时间，-1为永不过期，-2为已过期\n\n\n\ntype – 返回value的数据类型，只有String、List、Sorted List、Hash和Set这五种\nobject – 返回实现方式，比如embstr、int、raw等类型。redis默认会先以节省内存的编码方式创建，当满足一定条件时，会转换为更为通用的编码方式。\n\n\nString是二进制安全的一种数据类型，可以存储任何“可转换为string类型”的数据，其底层是SDS(simple dynamic string，简单动态字符串)。该数据结构会预先分配一定的capacity，然后在空间不足时分配更多capacity。\n\n注：capacity最大为512MB，小于1MB时空间进行翻倍，大于1MB时每次多分配1MB\n\n二进制安全二进制安全指的是redis基于字节流而非字符流，所有的内容都会转换成没有实际意义的二进制来存储。比如在C语言中有 “hello\\0world”，那么基于字符流时，会识别\\0，因此只能保存 “hello”；而基于字节流时，所有内容转换为二进制，\\0变为一串01序列，所以可以存储 “hello\\0world”。\n基本操作\nset &lt;key&gt; &lt;value&gt;设置键值对\nsetnx &lt;key&gt; &lt;value&gt;在key不存在时才设置\nget &lt;key&gt;获取值\nappend &lt;key&gt; &lt;str&gt;将str附加到值的尾部\nstrlen &lt;key&gt;获取值的长度&gt; set k1 100&gt; strlen k13&gt; append k1 A&gt; strlen k14   # “100A”&gt; set k2 中&gt; get k2# 此处的返回要根据预设的编码方式决定# 如果是GKB，则是2个hex# 如果是UTF8，则是3个hex# 如果设置了`redis-cli --raw`，则返回&quot;中&quot;&gt; strlen k2# 同上，需要根据编码方式决定\nincr/decr &lt;key&gt;值++/–\nincrby/decrby &lt;key&gt; &lt;step&gt;值+step/-step\nmset &lt;k1&gt; &lt;v1&gt; &lt;k2&gt; &lt;v2&gt; ...设置多个键值对(原子操作，任何一个失败则全部失败，不予设置)\nmget &lt;k1&gt; &lt;k2&gt;获取多个值\ngetrange &lt;key&gt; &lt;start&gt; &lt;end&gt;取key[start, end]，注意两边界可取\nsetrange &lt;key&gt; &lt;start&gt; &lt;value&gt;在start处插入一个value\ngetset &lt;key&gt; &lt;value&gt;获取旧值，设置新值\n\nList单键多值，底层为双向链表(quickList)，在数据量少时，使用一块连续内存，称为zipList，在数据量多时，将多个zipList作为节点，构建双向链表，称为quickList。\n常见操作\nlpush/rpush &lt;key&gt; &lt;v1, v2, ...&gt;从左侧/右侧压入数据\nrpoplpush &lt;k1&gt; &lt;k2&gt;从k1的右侧弹出元素放入k2的左侧\nlrange &lt;key&gt; &lt;start&gt; &lt;end&gt;key[start, end]\nlindex &lt;key&gt; &lt;index&gt;key[index]\nllen获取长度\nlinsert &lt;key&gt; before/after &lt;value&gt; &lt;newvalue&gt;在key[value]前/后插入一个newvalue\nlrem &lt;key&gt; &lt;n&gt; &lt;value&gt;\nblpop &lt;key&gt; &lt;timeout&gt; – 在timeout时间内阻塞等待弹出\n\n可实现的数据类型\n栈 – 通过同向插入删除即可\n队列 – 通过反向插入删除即可\n数组 – 使用LSET和LINDEX对单数据操作\n阻塞单播队列 – 使用BLPOP和BRPOP这种阻塞操作实现\n\nSet与list相似，但是不允许重复，底层是字典(hash表)，增删查改都是O(1)。\n\nsadd &lt;key&gt; &lt;v1, v2, ...&gt;\nsmembers &lt;key&gt;\nsismember &lt;key&gt; &lt;value&gt;if value in key?\nscard &lt;key&gt;返回个数\nsrem &lt;key&gt; &lt;v1, v2, ...&gt;删除\nspop &lt;key&gt;随机弹出一个\nsrandmember &lt;key&gt; &lt;n&gt;随机抽取n个\nsmove &lt;k1&gt; &lt;k2&gt;从k1移动一个到k2\nsdiffstore/sinterstore/sunionstore &lt;destkey&gt; &lt;k1&gt; &lt;k2&gt;将k1与k2进行操作放入destkey\nsdiff/sinter/sunion &lt;key ...&gt;操作后输出\n\nHash存储的是 {key: {field: value, field: value}} 的结构。\n基本操作\nhset &lt;key&gt; &lt;field&gt; &lt;value&gt;\nhget &lt;key&gt; &lt;field&gt;\nhmset &lt;key&gt; &lt;field1&gt; &lt;value1&gt; &lt;field2&gt; &lt;value2&gt;...\nhexists &lt;key&gt; &lt;field&gt;\nhvals/hkeys &lt;key&gt;查看所有value/key\n\nZset与set类似，但是是有序的，因为其为每个成员设置了一个score用于排序。底层使用了两种数据结构：\n\nhash: {key: {value: score}}\n跳表\n\n基本操作\nzadd &lt;key&gt; &lt;s0&gt; &lt;value0&gt; &lt;s1&gt; &lt;value1&gt; ...\nzrange &lt;key&gt; &lt;start&gt; &lt;end&gt; [withscores]\nzrangebyscore &lt;key&gt; &lt;min&gt; &lt;max&gt; [withscores]从大到小排序\nzrevrangebyscore ...反序\nzcount &lt;key&gt; &lt;min&gt; &lt;max&gt;范围内的元素个数\nzrank &lt;key&gt; &lt;value&gt;返回排名，从0开始计数\nzrem &lt;key&gt; &lt;value&gt;删除\n\nBitmaps实际上是字符串，但可以视为只能存储0和1，其下标被称为“偏移量”，用于提高内存使用率。\n基本操作\nsetbit &lt;key&gt; &lt;offset&gt; &lt;value&gt;(注意是从最左边开始算offset，且STRLEN返回的是字节数而非比特数)&gt; setbit k1 1 101000000            # 从左边开始算偏移&gt; STRLEN k11                   # 返回字节数&gt; setbit k1 1 90100000001000000    # 仍然是从最左边开始算偏移 &gt; STRLEN k12                   \ngetbit &lt;key&gt; &lt;offset&gt;\nbitop and/or/not/xor &lt;destkey&gt; &lt;key&gt; [key...]\nbitcount &lt;key&gt; [start] [end]用于记录为1的个数，注意此处是针对8个bits，即一个byte为单位\nbitpos &lt;key&gt; &lt;bit&gt; [start] [end]用于查询第start~第end个字节内第一个bit元素的偏移量(仍然是从最左边开始计算偏移量)&gt; set k1 1 1&gt; set k1 9 1&gt; get k101000000 01000000&gt; bitpos k1 1 0 01   # 第0个字节内第一个1的偏移量&gt; bitpos k1 1 1 19   # 第1个字节内第一个1的偏移量，注意仍然是从最左侧计算偏移，所以是9而非1\n\n使用场景\n统计登录天数\n\n每一个key代表一个用户，value中保存了365个bit，用于代表每一天。该用户在第i天登录，那么setbit user i 1，即把第i个bit设置为1代表登录了。\n如果想要知道某个用户user的登录天数，那么只需要bitcount user 0 -1即可。\n\n统计活跃用户\n\n每一个key代表一天，value中每一个bit代表一个用户。如果用户i在当天登录，那么setbit date i 1。\n如果定义每一天都登录的为活跃用户，那么只需要bitop and [date ...]，再统计最后结果中有多少个为1即代表由多少活跃用户。\nHyperLogLog用于做基数统计。在输入数据巨大时，计算基数所需的空间总是固定且较小的，比如在Redis中可以用12KB计算264个基数。\n\n基数：不重复的数字个数\n\n\npfadd &lt;key&gt; &lt;element ...&gt;\npfcount &lt;key&gt;\npfmerge &lt;destkey&gt; &lt;key1, key2 ...&gt;将多个Log进行合并\n\nGEO主要用于保存地理信息，可以计算直线距离等\n\nredis-benchmark 压测使用redis-benchmark可以进行压力测试。\n\n-h – 测试的主机ip\n-p – 端口\n-c – 并发数(concurrency)\n-n – 请求数\n\n\nLua脚本Lua是一种非常轻量级的脚本语言，一般使用C语言编写，其设计目的是为了嵌入应用程序中，从而为应用程序提供灵活的扩展和定制功能。\n为什么要使用Lua\n减少网络开销(类似pipeline)：多个请求通过脚本一次发送，减少网络延迟\n原子操作(类似事务)：将脚本作为一个整体执行，中间不会插入其他命令，无需使用事务\n复用：客户端发送的脚本永久存在redis中，其他客户端可以复用脚本\n可嵌入性：可嵌入JAVA，C#等多种编程语言，支持不同操作系统跨平台交互\n\n如何使用Lua\nEVAL script numkeys key [key ...] arg [arg ...]\n\n其中script是脚本的内容或路径，numkeys为传入的key的个数，然后key和arg分别对应Lua脚本中的 KEYS[1] KEYS[2] … 和 ARGV[1] ARGV[2] …\n\nSCRIPT LOAD script\n\n返回脚本的SHA1校验和，不执行\n\nEVALSHA sha1 numkeys key [key ...] arg [arg ...]\n\n根据传入的 sha1 校验和执行脚本\n\n权限控制ACL(Access Control List)访问控制列表：允许设置可执行的命令和可访问的键来限制用户操作，从而对用户进行更细粒度的权限控制\n\nacl list – 列出用户信息和权限\nacl setuser – 新建用户，并可以设置其权限\nacl cat – 查看指令\nacl whoami – 显示当前用户\nauth &lt;username&gt; &lt;password&gt; – 切换用户\n\n\n","categories":["Redis"],"tags":["redis"]},{"title":"WSGI","url":"/2021/04/26/WSGI/","content":"什么是WSGIWSGI规范的目的就是解耦 Web Server 和 Web Application。 一个完整的WSGI协议包括 server 和 appliction 两部分。\n其中，像 gunicorn, uwsgi 就是实现的 server 端，而 Django, Flask 则是实现的 application 端。这样一来，我们就可以像搭积木一样随意组合web server 和 web framework了。\n\nWSGI规定，Web程序必须有一个可调用对象，且该可调用对象接收两个参数，返回一个可迭代对象：\n\nenviron：字典，包含请求的所有信息\nstart_response：在可调用对象中调用的函数，用来发起响应\n\n下面实现一个最简单的 application :\ndef helloWorld(environ, start_response):    status_code = &#x27;200 OK&#x27;    header = [(&#x27;Content-Type&#x27;, &#x27;text/html&#x27;)]    start_response(status_code, header) # 用于发送HTTP header    body = &#x27;&lt;h1&gt;Hello, %s!&lt;/h1&gt;&#x27; % (environ[&#x27;PATH_INFO&#x27;][1:] or &#x27;World&#x27;)    return [body.encode(&#x27;utf-8&#x27;)]\n\n然后再编写一个 server 函数：\n# 从wsgiref模块导入:from wsgiref.simple_server import make_server# 导入application函数:import helloWorld# 创建一个服务器，IP地址为空，端口是8000，处理函数是helloWorld:httpd = make_server(&#x27;127.0.0.1&#x27;, 8000, helloWorld)# 开始监听HTTP请求:httpd.serve_forever()\n\n\n如果输入的url为127.0.0.1/那么输出的是Hello World；如果输入的url为127.0.0.1/kexin那么输出的是Hello kexin。\n\n\n在 Django 中，有一个wsgi.py定义了上述的相关内容：\n&#x27;&#x27;&#x27;    wsgi.py&#x27;&#x27;&#x27;import osfrom django.core.wsgi import get_wsgi_applicationos.environ.setdefault(&#x27;DJANGO_SETTINGS_MODULE&#x27;, &#x27;config.settings&#x27;)  # 从setting读取参数初始化WSGI# 将用户编写的代码整合成一个application# 这样web server调用此处的application就相当于上面调用helloWorld一样application = get_wsgi_application()    \n\n","categories":["Web","Django"],"tags":["概念","web","Django"]},{"title":"ab并发测试","url":"/2021/05/12/ab%E5%B9%B6%E5%8F%91%E6%B5%8B%E8%AF%95/","content":"什么是abab是Apache HTTP server benchmarking tool的缩写，可以用以测试HTTP请求的服务器性能,也是业界比较流行和简单易用的一种压力测试工具包。\n使用ab在终端中切换至安装ab的bin目录下，然后输入ab -n &lt;requestNum&gt; -c &lt;concurrencyNum&gt; &lt;destination&gt;\n\nrequestNum: 表示发送请求的数量\nconcurrencyNum: 表示并发请求的数量\ndestination: 表示请求的目标\n\n\n注：如果提示 SSL not compiled in; no https support，请使用abs代替ab\n\nab中常见的概念吞吐率(Requests per second)用于描述服务器处理并发的能力，指的是某个并发用户数量下单位时间内处理的请求数量。\n并发连接数(The number of concurrent connections)某个时刻服务器所接受的请求数目\n并发用户数(Concurrency level)由于一个用户可能发起多个请求，所以并发用户数≤并发连接数\n用户平均等待时间处理完所有请求的时间 / (总请求数 / 并发用户数)\n服务器平均请求等待时间处理完所有请求的时间 / 总请求数 = 吞吐率-1 = 用户平均请求等待时间 / 并发用户数\n","categories":["软件测试"],"tags":["软件测试"]},{"title":"caffe2pytorch","url":"/2021/04/20/caffe2pytorch/","content":"Caffe2PyTorchThis cookbook is a guide about how to transfer Caffe layers to PyTorch functions and networks.\n\nnn.Conv2dnn.Conv2d(in_channels, out_channels, kernel_size, padding, stride, bias)\nlayer &#123;  name:   type: &quot;Convolution&quot;  bottom:   top:   convolution_param &#123;    num_output: 64    bias_term: true    pad: 3    kernel_size: 7    stride: 2    weight_filler &#123;      type: &quot;msra&quot;    &#125;  &#125;&#125;\n\n\nnn.BatchNorm2dnn.BatchNorm2d(out_channels)\nlayer &#123;  name:   type: &quot;BatchNorm&quot;  bottom:   top:   batch_norm_param &#123;    use_global_stats: false  &#125;&#125;layer &#123;  name:   type: &quot;Scale&quot;  bottom:   top:   scale_param &#123;    bias_term: true  &#125;&#125;\n\n\nnn.ReLUnn.ReLU(inplace=True)\nlayer &#123;  name:   type: &quot;ReLU&quot;  bottom:   top: &#125;\n\n\ntorch.reshapetorch.reshape(x, (n, c, -1)) # caffe中dim=0表示维度不变\nlayer &#123;  name:   type: &quot;Reshape&quot;  bottom:   top:   reshape_param &#123;    shape &#123;      dim: 0      dim: 0      dim: -1    &#125;  &#125;&#125;\n\n\ntorch.transposetorch.transpose(x, dim_0, dim_1)    # torch的transpose只能一次交换两个维度，多个维度需要多次交换\nlayer &#123;  name:   type: &quot;TensorTranspose&quot;  bottom:   top:   tensor_transpose_param &#123;    order: 0    order: 2    order: 1  &#125;&#125;\n\n\ntorch.bmmtorch.bmm(x, y) # bmm针对batch做矩阵乘法，即(n, c, w, h)，如果是(c, w, h)则可以使用bm\nlayer &#123;  name:   type: &quot;MatrixMultiplication&quot;  bottom:   bottom:   top: &#125;\n\n\nF.softmaxF.softmax(x, dim)   # dim即为下面的axis\nlayer &#123;  name:   type: &quot;Softmax&quot;  bottom:   top:   softmax_param &#123;    axis: 2  &#125;&#125;\n\n\nCropclass Crop(nn.Module):    &#x27;&#x27;&#x27;        @ axis      -&gt;      从axis开始裁减后面的维度        @ offset    -&gt;      裁减的时候要偏离多少距离        ! 注意：在Caffe中，是以B的大小来裁减A，即 B.shape &lt;= A.shape    &#x27;&#x27;&#x27;    def __init__(self, axis, offset=0):        super(Crop, self).__init__()        self.axis = axis        self.offset = offset    def forward(self, x, ref):        for axis in range(self.axis, x.dim()):            ref_size = ref.size(axis)            indices = torch.arange(self.offset, self.offset + ref_size).long()            indices = x.data.new().resize_(indices.size()).copy_(indices)            x = x.index_select(axis, indices.to(torch.int64))        return x\nlayer &#123;  name:   type: &quot;Crop&quot;  bottom: A  bottom: B  top:   crop_param &#123;    axis: 2  &#125;&#125;\n\n\nEltwiseclass Eltwise(nn.Module):    def __init__(self, operation=&#x27;+&#x27;):        super(Eltwise, self).__init__()        self.operation = operation    def forward(self, *inputs):        if self.operation == &#x27;+&#x27; or self.operation == &#x27;SUM&#x27;:            x = inputs[0]            for i in range(1,len(inputs)):                x = x + inputs[i]        elif self.operation == &#x27;*&#x27; or self.operation == &#x27;MUL&#x27;:            x = inputs[0]            for i in range(1,len(inputs)):                x = x * inputs[i]        elif self.operation == &#x27;/&#x27; or self.operation == &#x27;DIV&#x27;:            x = inputs[0]            for i in range(1,len(inputs)):                x = x / inputs[i]        elif self.operation == &#x27;MAX&#x27;:            x = inputs[0]            for i in range(1,len(inputs)):                x =torch.max(x, inputs[i])        else:            print(&#x27;forward Eltwise, unknown operator&#x27;)        return x\n\nlayer &#123;  name:   type: &quot;Eltwise&quot;  bottom:   bottom:   top: &#125;layer &#123;  name:   type: &quot;Eltwise&quot;  bottom:   bottom:   top:   eltwise_param &#123;    operation: PROD  &#125;&#125;\n\n\nnn.ConvTranspose2dnn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, output_padding, groups, bias)\nlayer &#123;  name:   type: &quot;Deconvolution&quot;  bottom:   top:   param &#123;    lr_mult: 0.0  &#125;  convolution_param &#123;    num_output: 128    bias_term: false    pad: 0    kernel_size: 4    group: 128    stride: 2    weight_filler &#123;      type: &quot;bilinear&quot;    &#125;  &#125;&#125;\n\n\nConcatclass Concat(nn.Module):    def __init__(self, axis):        super(Concat, self).__init__()        self.axis = axis    def forward(self, *inputs):        return torch.cat(inputs, self.axis)\n\nlayer &#123;  name:   type: &quot;Concat&quot;  bottom:   bottom:   bottom:   top:   propagate_down: true  propagate_down: true  propagate_down: false  concat_param &#123;    concat_dim: 1  &#125;&#125;\n","categories":["Deep Learning"],"tags":["CV"]},{"title":"hexo-pdf","url":"/2021/04/18/hexo-pdf/","content":"If you want to insert .pdf files in your HEXO pages, there are two methods.\n\nMETHOD 0\n\nYou can install HEXO package hexo-pdf.\nnpm install --save hexo-pdf\n\nThen, you can use .ejs syntax &#123;% pdf path %&#125; to achieve function.\n&#123;% pdf https:&#x2F;&#x2F;drive.google.com&#x2F;xxx %&#125;  # external url&#123;% pdf .&#x2F;xxx.pdf %&#125;                     # file path\n\n\nMETHOD 1\n\nIn your index.md, you can use html syntax to achieve this function.\n&lt;object data=&quot;https://drive.google.com/xxx&quot; type=&quot;application/pdf&quot; width=&quot;100%&quot; height=&quot;100%&quot;&gt;&lt;object data=&quot;./xxx.pdf&quot; type=&quot;application/pdf&quot; width=&quot;100%&quot; height=&quot;100%&quot;&gt;\n\n\nYou can adjust the width and height even other properties.\n\n","categories":["Web","HEXO"],"tags":["web","hexo"]},{"title":"云服务IaaS,PaaS和SaaS","url":"/2021/05/25/%E4%BA%91%E6%9C%8D%E5%8A%A1IaaS-PaaS%E5%92%8CSaaS/","content":"云服务就以存储举例。\n在之前，如果A要存储100G的资源，需要买一个大于100G的硬盘，比如买一个500G的，那么就浪费了400G，但是钱还是一样花了。同样，如果有一天，A的资源增加到501G，那么他需要再买新的硬盘专门存储1G的资源。\n而云存储（云服务的一种）就类似于A要存储100G，B要存储50G，那么A和B可以存储在一个500G的空间内。即物理上存储在一起，逻辑上是独立的，A不能访问B的资源，反之亦然。当B增加到480G时，可以将多余的30G存储到另一个物理地址上，这就牵涉到分布式系统。\n常见的三种云服务模式为IaaS、PaaS和SaaS。\n\nIaaSInfrastructure as a Service，基础设施即为服务。\n由云服务提供商把 IT 系统的基础设施建设好，并对计算设备进行池化，然后直接对外出租硬件服务器、虚拟主机、存储或网络设施（负载均衡器、防火墙、公网IP地址及诸如 DNS 等基础服务）等。\n云服务提供商负责管理机房基础设施、计算机网络、磁盘柜、服务器和虚拟机，租户自己安装和管理操作系统、数据库、中间件、应用软件和数据信息，所以 IaaS 云服务的消费者一般是掌握一定技术的系统管理员。\nPaaSPlatform as a Service，平台即服务。\n云服务提供商把 IT 系统的平台软件层作为服务出租出去。相比于 IaaS 云服务提供商，PaaS 云服务提供商要做的事情增加了，他们需要准备机房、布好网络、购买设备、安装操作系统、数据库和中间件，即把基础设施层和平台软件层都搭建好，然后在平台软件层上划分“小块”（习惯称之为容器）并对外出租。\nPaaS 云服务提供商也可以从其他 IaaS 云服务提供商那里租赁计算资源，然后自己部署平台软件层。另外，为了让消费者能直接在云端开发调试程序，PaaS 云服务提供商还得安装各种开发调试工具。相反，租户要做的事情相比 IaaS 要少很多，租户只要开发和调试软件或者安装、配置和使用应用软件即可。\nSaaSSoftware as a Service，软件即服务。\n软件部署在云端，让用户通过因特网来使用它，即云服务提供商把 IT 系统的应用软件层作为服务出租出去，而消费者可以使用任何云终端设备接入计算机网络，然后通过网页浏览器或者编程接口使用云端的软件。这进一步降低了租户的技术门槛，应用软件也无须自己安装了，而是直接使用软件。\n总结用生活中的例子来描述。比如提供服务类似于做饭，那么：\n\nIaaS 相当于提供刀叉、锅碗瓢盆等这些硬件设施(基础设施)，用户需要自己准备食材(开发套件，OS，DB等)，还需要自己烹饪(写软件代码)\nPaaS 相当于提供刀叉、锅碗瓢盆和切好的食材(基础设施和开发套件)，用户只需要自己烹饪(写代码)\nSaaS 相当于直接上菜，用户什么都不用做，只要使用饭店提供的筷子、刀叉(API，UI界面等)吃饭即可\n\n","categories":["概念","云"],"tags":["概念"]},{"title":"消息队列&订阅发布","url":"/2021/05/24/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-%E8%AE%A2%E9%98%85%E5%8F%91%E5%B8%83/","content":"什么是消息队列(MQ)不论是Kafka还是RabbitMQ，消息队列的功能都可以概括为：一收一发。消息队列就如其名一样，是基于队列的数据结构。\n为什么要加入消息队列那么为什么需要在Client和Server中间多加这样一个层呢？\n\n解耦：通过加入消息队列，可以将队列两端的业务逻辑完全隔离开。生产者只需要关注于向队列中加入数据，而不用在意消费者；消费者只需要关注于从队列中取数据，完全不关心生产者。\n临时持久化：有时在处理数据的时候处理过程会失败。如果没有消息队列，数据处理失败后需要重新向生产者索要数据，而有了队列后，直接再次从队列中取出数据即可。在被许多消息队列所采用的”插入-获取-删除”范式中，在把一个消息从队列中删除之前，需要你的处理过程明确的指出该消息已经被处理完毕，确保你的数据被安全的保存直到使用完毕。\n削峰：服务器的处理能力有限，如果突然出现高并发，那么服务器可能承受不了而崩溃。引入消息队列后，只要把数据全部存到消息队列，服务器再慢慢处理即可。\n异步加速：如果没有消息队列，那么任务需要串行完成，这需要等待漫长的网络连接和数据库的IO读写。如果有了消息队列，可以待任务丢入消息队列后即给Clinet返回消息，然后数据库再慢慢通过IO和网络处理消息队列的内容。\n\n\n消息队列 &rarr; 订阅发布\n消息队列如图的左边，只能点对点（一对一），如果要将消息分发给不同的消费者，就需要更复杂的逻辑。\n因此就像图的右边，订阅发布出现了。订阅者需要先订阅指定的发布者。发布者只需要把内容放进消息队列；消息队列内容弹出时，该消息（主题）只会分发给 订阅了生产该消息的发布者 对应的订阅者。\n\n假设订阅者0、1订阅了发布者A；订阅者1、2订阅了发布者B。那么当消息队列取出“发布者A发布的消息时”，该消息只会分发给订阅者0和1，订阅者2无法接收到。\n\n","categories":["Web","概念","消息队列"],"tags":["概念","web","消息队列"]},{"title":"编译型语言和解释型语言","url":"/2021/04/19/%E7%BC%96%E8%AF%91%E5%9E%8B%E8%AF%AD%E8%A8%80%E5%92%8C%E8%A7%A3%E9%87%8A%E5%9E%8B%E8%AF%AD%E8%A8%80/","content":"编译型语言和解释型语言计算机是不能理解高级语言的，更不能直接执行高级语言，它只能直接理解机器语言，所以使用任何高级语言编写的程序若想被计算机运行，都必须将其转换成计算机语言，也就是机器码。而转换主要有两种方法\n\n编译 – 先进行转换，然后再运行\n\n解释 – 运行的过程中进行转换\n\n\n编译型语言使用专门的编译器，针对特定的平台，将高级语言源代码一次性的编译成可被该平台硬件执行的机器码，并包装成该平台所能识别的可执行性程序的格式(如.exe)。由于已经生成了可执行格式，以后运行时不需要编译，所以编译型语言执行效率高(编译一次，多次使用)。\n一般而言，编译型语言有以下特点：\n\n编译后无需再次编译，性能好\n针对特定平台，跨平台性能差\n\n由于有以上的特点，所以编译型语言常用于OS，嵌入式等对性能要求极高的特定平台，所以衍生出的经典语言类型有 – C/C++\n解释型语言使用专门的解释器对源程序逐行解释成特定平台的机器码并立即执行。是代码在执行时才被解释器一行行动态翻译和执行，而不是在执行之前就完成翻译。\n一般而言，解释型语言有以下特点：\n\n由于在执行时再翻译，每次执行都要翻译，效率低\n只要对应平台有相应的解释器即可运行，跨平台性能好，便于移植\n\n由于有以上的特点，所以解释型语言常用于Web，脚本等跨平台使用的场景，所以衍生出的经典语言类型有 – Python, Javascript\n关于JavaJava是一种很特殊的语言，其需要将.java文件通过编译生成.class文件，但是该.class文件却可以在各种平台上使用，因为java针对不同的平台有不同的JVM，实现了跨平台。\n\n\n你可以说它是编译型的：因为所有的Java代码都是要编译的，.java不经过编译就什么用都没有。 \n你可以说它是解释型的：因为java代码编译后不能直接运行，它是解释运行在JVM上的，所以它是解释运行的，那也就算是解释的了。 \n但是，现在的JVM为了效率，都有一些JIT优化。它又会把.class的二进制代码编译为本地的代码直接运行，所以，又是编译的。\n\n\n\n为什么需要编译编译有两个主要的好处：\n\n可以提前排除错误;\n对于Java而言，编译并不会直接像C++一样产生基于特定系统的机器码，而是会产生一个二进制比特文件(又称为class文件)，这个文件可以在多种平台被识别(通过JVM)，然后再基于特定的系统进一步进行翻译，实现跨平台与高效率的trade-off\n\n","categories":["概念","Java","概念","编译原理"],"tags":["概念"]},{"title":"软件并发情形下的常见指标","url":"/2021/05/24/%E8%BD%AF%E4%BB%B6%E5%B9%B6%E5%8F%91%E6%83%85%E5%BD%A2%E4%B8%8B%E7%9A%84%E5%B8%B8%E8%A7%81%E6%8C%87%E6%A0%87/","content":"响应时间(RT)响应时间是指系统对请求作出响应的时间。\n对于单机的没有并发操作的应用系统而言，人们普遍认为响应时间是一个合理且准确的性能指标。需要指出的是，响应时间的绝对值并不能直接反映软件的性能的高低，软件性能的高低实际上取决于用户对该响应时间的接受程度。\n吞吐量(Throughput)吞吐量是指系统在单位时间内处理请求的数量。\n对于无并发的应用系统而言，吞吐量与响应时间成严格的反比关系，实际上此时吞吐量就是响应时间的倒数。\n对于单用户的系统，响应时间（或者系统响应时间和应用延迟时间）可以很好地度量系统的性能，但对于并发系统，通常需要用吞吐量作为性能指标。\n并发用户数并发用户数是指系统可以同时承载的正常使用系统功能的用户的数量。与吞吐量相比，并发用户数是一个更直观但也更笼统的性能指标。实际上，并发用户数是一个非常不准确的指标，因为用户不同的使用模式会导致不同用户在单位时间发出不同数量的请求。\n每秒查询率(QPS)每秒查询率是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准，可以认为是每秒的响应请求数，也即是最大吞吐能力。\n","categories":["软件测试"],"tags":["软件测试"]},{"title":"远程过程调用RPC","url":"/2021/05/23/%E8%BF%9C%E7%A8%8B%E8%BF%87%E7%A8%8B%E8%B0%83%E7%94%A8RPC/","content":"RPCRPC是远程过程调用（Remote Procedure Call）的缩写形式。\n具体而言，比如说有两台服务器A和B，想要在A调用B中的函数int B_function(int a, int b)，那么就需要使用RPC功能。\n同一主机时在同一台主机上时，调用int B_function(int a, int b)有如下步骤：\nint a = 10;int b = 20;int c = B_function(a, b);\n\n\n将 a=10 和 b=20 的值压栈\n进入 B_function 函数，取出栈中的值 10 和 20，将其赋予 a 和 b 的形参\n执行代码，并将结果存在一个临时变量 temp 中\n将 temp 的值压栈，然后函数弹出栈\n返回断点处，从栈中取出返回值 temp，并赋值给 c\n\n不同主机时但是在不同的主机中，由于内存并不共享，所以会引入新的各种问题：\n\nCall ID映射。我们怎么告诉远程机器我们要调用B_function，而不是C_function或者D_function呢？在本地调用中，函数体是直接通过函数指针来指定的，我们调用B_function，编译器就自动帮我们调用它相应的函数指针。但是在远程调用中，函数指针是不行的，因为两个进程的地址空间是完全不一样的。所以，在RPC中，所有的函数都必须有自己的一个ID。这个ID在所有进程中都是唯一确定的。客户端在做远程过程调用时，必须附上这个ID。然后我们还需要在客户端和服务端分别维护一个 {函数 &lt;–&gt; Call ID} 的对应表。两者的表不一定需要完全相同，但相同的函数对应的Call ID必须相同。当客户端需要进行远程调用时，它就查一下这个表，找出相应的Call ID，然后把它传给服务端，服务端也通过查表，来确定客户端需要调用的函数，然后执行相应函数的代码。\n\n序列化和反序列化。客户端怎么把参数值传给远程的函数呢？在本地调用中，我们只需要把参数压到栈里，然后让函数自己去栈里读就行。但是在远程过程调用时，客户端跟服务端是不同的进程，不能通过内存来传递参数。甚至有时候客户端和服务端使用的都不是同一种语言（比如服务端用C++，客户端用Java或者Python）。这时候就需要客户端把参数先转成一个字节流，传给服务端后，再把字节流转成自己能读取的格式。这个过程叫序列化和反序列化。同理，从服务端返回的值也需要序列化反序列化的过程。\n\n网络传输。远程调用往往用在网络上，客户端和服务端是通过网络连接的。所有的数据都需要通过网络传输，因此就需要有一个网络传输层。网络传输层需要把Call ID和序列化后的参数字节流传给服务端，然后再把序列化后的调用结果传回客户端。只要能完成这两者的，都可以作为传输层使用。因此，它所使用的协议其实是不限的，能完成传输就行，比如选用TCP/IP协议。\n\n\n总结一下上述的过程如下：\n&#x2F;&#x2F; Client端 1. 将这个调用映射为Call ID。这里假设用最简单的字符串当Call ID的方法2. 将Call ID，a和b序列化。可以直接将它们的值以二进制形式打包3. 把2中得到的数据包发送给ServerAddr，这需要使用网络传输层4. 等待服务器返回结果5. 如果服务器调用成功，那么就将结果反序列化，并赋给c&#x2F;&#x2F; Server端1. 在本地维护一个Call ID到函数指针的映射call_id_map2. 等待请求3. 得到一个请求后，将其数据包反序列化，得到Call ID4. 通过在call_id_map中查找，得到相应的函数指针5. 将a和b反序列化后，在本地调用函数，得到结果6. 将结果序列化后通过网络返回给Client","categories":["概念"],"tags":["概念"]},{"title":"锁的类型以及分布式锁","url":"/2021/05/24/%E9%94%81%E7%9A%84%E7%B1%BB%E5%9E%8B%E4%BB%A5%E5%8F%8A%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/","content":"乐观锁 &amp; 悲观锁\n乐观锁认为，多个线程共享资源时很少会更改共享资源，所以先分配，工作完成后再看资源是否被更改，如果被更改则放弃此次操作；\n悲观锁认为，线程会更改共享资源，所以每次只能让一个线程占用资源。\n\n\n互斥锁 &amp; 自旋锁\n互斥锁认为，当A占用资源，B想要访问资源时，加锁失败，此时B会释放CPU，进行线程的上下文切换 (时间开销大)\n自旋锁认为，当A占用资源，B想要访问资源时，加锁失败，B不会释放CPU，而是进入忙等待，不用切换上下文\n\n\n分布式锁关于分布式锁，可以参考Redis进阶中关于分布式锁的介绍。其主要功能就是控制数据的一致性。\n在加入分布式锁后，是否还有必要实现类似JVM的锁？ 毕竟分布式锁已经实现了数据一致性。\n该问题的答案是“有必要”，因为分布式锁只是实现了多个线程只有一个能占用资源，但是多个线程来不同的主机，加入JVM锁后可以减少IO的负担，即每个主机推选出一个线程来和其他主机竞争锁即可。\n\n","categories":["OS","概念","OS","锁"],"tags":["分布式","概念","OS"]},{"title":"Java基础","url":"/2021/05/28/Java%E5%9F%BA%E7%A1%80/","content":"Java概述Java运行方法Java是一种很特殊的语言。其 源文件.java，而其通过编译生成 字节码文件.class，该.class文件再被执行。\njavac xxx.java  # 编译 -&gt; 生成.classjava xxx        # 运行.class\n上述javac为编译器，java为解释器。\n\n\n你可以说它是编译型的：因为所有的Java代码都是要编译的，.java不经过编译就什么用都没有。 \n你可以说它是解释型的：因为java代码编译后不能直接运行，它是解释运行在Java虚拟机上的，所以它是解释运行的，那也就算是解释的了。 \n\n\n常见名词解释JVMJava Virtual Machine，实现Java跨平台的核心。本质上来说，JVM并不是跨平台的，需要根据不同的操作系统选择不同的JVM，但是，对于java源文件（代码）而言，只要有JVM，就可以直接运行，不用在乎运行的平台（操作系统）。\nJREJava Runtime Environment，是Java的运行环境，包含JVM和核心库。如果只需要运行Java文件，则可以只安装JRE。\nJDKJava Development Kit，是程序开发工具组件，包含JRE和其他工具。如果要开发项目，编写Java代码，则必须安装JDK。\n\nJava源文件格式\n一个源文件只能有一个public的class\n一个源文件可以有多个非public的class\n源文件的文件名要和public的class一致\npackage语句放在源文件首行，import紧随其后，然后再是class定义\n一个项目(不是一个文件，一个项目可以有多个文件构成)中只能有一个main函数，且该main函数是该项目的起点\n该main函数有特定的定义方式和参数名，即public static void main(String[] args) &#123;...&#125;\n\npackage HelloWorld// HelloWorld.javapublic class HelloWorld &#123;    public static void main(String[] args) &#123;        ...    &#125;&#125; \n\n\nJava数据类型变量就是申请内存来存储值。也就是说，当创建变量的时候，需要在内存中申请空间。内存管理系统根据变量的类型为变量分配存储空间，分配的空间只能用来储存该类型数据。\nJava两大数据类型：基本数据类型，引用数据类型。\n基本数据类型\nbyte (8 bit)\n\nbyte 用在大型数组中节约空间，主要代替整数，因为 byte 变量占用的空间只有 int 类型的四分之一\n\nshort (16 bit)\nint (32 bit)\nlong (64 bit)\nfloat (32 bit 单精度)\ndouble (64 bit 双精度)\nboolean (1 bit，true / false)\nchar (16 bit，用&#39;&#39;标记)\n\n\n整数类型默认为int，如果要为long，则需要加上一个L后缀；浮点数类型默认为double，如果要为float，则需要加上一个F后缀。\n\n\n使用Integer.SIZE查看所用的bit数，使用Integer.MIN_VALUE、Integer.MAX_VALUE查看范围\n\n引用数据类型\n在Java中，引用类型的变量非常类似于C/C++的指针。引用类型指向一个对象，指向对象的变量是引用变量。\n对象、数组都是引用数据类型。\n所有引用类型的默认值都是null。\n一个引用变量可以用来引用任何与之兼容的类型。（比如指向父类的指针同样可以指向子类）\n\n\nJava类型转换自动类型转换低  ------------------------------------&gt;  高byte,short,char—&gt; int —&gt; long—&gt; float —&gt; double \n\n\n不能对boolean类型进行类型转换。\n不能把对象类型转换成不相关类的对象。\n在把容量大的类型转换为容量小的类型时必须使用强制类型转换。\n转换过程中可能导致溢出或损失精度\n浮点数到整数的转换是通过舍弃小数得到，而不是四舍五入\n\n强制类型转换type var = (type)otherTypeVar;\n\n\nJava类变量类型对于class而言，主要有三种：局部变量、静态变量（类变量）和实例变量。\nclass Student &#123;    static String class = &quot;1704&quot;;   // 类变量    String name = &quot;tom&quot;;            // 实例变量    void function() &#123;        int score = 100;            // 局部变量    &#125;&#125;\n\n局部变量定义在类内方法中的变量，当超过某个特定方法区域后，就丧失作用。访问修饰符(private, public等)不能用于局部变量，因为其存储在栈上，到达方法结尾即被销毁，后续也无法访问。\n实例变量实例变量声明在一个类中，但在方法、构造方法和语句块之外。当一个对象被实例化之后，每个实例变量的值就跟着确定。实例变量在对象创建的时候创建，在对象被销毁的时候销毁。\n实例变量需要将class new一个对象，然后使用 objectName.value 来进行访问。\n\n比如创建一个class用于表示中国居民的信息，那么每个人名字是和具体的类对象相关的，因人而异，所以需要定义成实例变量，给每个人分配相应的名字。\n\n类变量类变量也称为静态变量，在类中以 static 关键字声明，但必须在方法之外。静态变量在第一次被访问时创建，在程序结束时销毁。\n\n无论一个类创建了多少个对象，类只拥有类变量的一份拷贝。\n静态变量初始化后不可改变。\n静态变量储存在静态存储区。\n使用 className.value 进行访问\n\n\n比如创建一个class用于表示中国居民的信息，那么每个人的国籍是和整个类相关的，此问题中国籍就可以设置成类变量，只要访问任意一个该类的实例都可以得到相同的国籍。\n\n\nJava修饰符访问控制修饰符详见class内的介绍，点击此处。\n非访问控制修饰符static\n静态变量：static 关键字用来声明独立于对象的静态变量，无论一个类实例化多少对象，它的静态变量只有一份拷贝。 静态变量也被称为类变量。局部变量不能被声明为 static 变量。\n\n静态方法：static 关键字用来声明独立于对象的静态方法。静态方法不能使用类的非静态变量。静态方法从参数列表得到静态数据，然后计算这些数据。同样，静态方法不能使用this关键字。\n\n\nfinal\nfinal变量：一旦赋值后，不能被重新赋值。其值在初始化时被固定，该初始化过程可以是直接赋值、运算或者是构造函数等。final + static == const\n\nfinal类：使用final限定的class不能被继承。\n\nfinal方法：使用final限定的方法在子类中不能被重写。\n\n\nabstract\nabstract 类：\n\n该类不能被new，只能被后续继承。\n一个类不能同时被 abstract 和 final 修饰。\n如果一个类包含抽象方法，那么该类一定要声明为抽象类，否则将出现编译错误。\n抽象类可以包含抽象方法和非抽象方法。\n\n\nabstract 方法\n\n该方法无实现方法，只能被后续重写。\n抽象方法不能被声明成 final 和 static。\n任何继承抽象类的子类必须实现父类的所有抽象方法，除非该子类也是抽象类。\n如果一个类包含若干个抽象方法，那么该类必须声明为抽象类。抽象类可以不包含抽象方法。\n抽象方法的声明以分号结尾，例如：public abstract function();\n\n\n\nsynchronized\nsync定义的方法同一时间只能被一个线程访问。\n\ntransient\n被transient修饰的变量会被JVM跳过，不被持久化。\n\nvolatile\n每次线程访问volatile定义的变量时，都要从内存中重新读取该值。当该值变化时，会强制线程将新的值写到内存。因此，多个线程总能看到变量的同一个值。\n\n\n运算绝大部分运算都和C++高度一致。\n此处介绍instanceof运算，用于判断某个变量是否属于某个类型。\nString name = &quot;tom&quot;;System.out.println(name instanceof String); // true\n\n\n循环for循环和while循环和C++高度类似。\n此处介绍加强版for循环(又称for plus pro max)。\nfor(声明语句 : 表达式)&#123;    ...&#125;\n\n\n\n声明语句：声明新的局部变量，该变量的类型必须和数组元素的类型匹配。其作用域限定在循环语句块，其值与此时数组元素的值相等。\n表达式：表达式是要访问的数组名，或者是返回值为数组的方法。\n\n\n\n分支与C++高度类似，不多BB。\n\nNumber类 &amp; Math类所有的包装类（Integer、Long、Byte、Double、Float、Short）都是抽象类 Number 的子类。\n这种由编译器特别支持的包装称为装箱，所以当内置数据类型被当作对象使用的时候，编译器会把内置类型装箱为包装类。相似的，编译器也可以把一个对象拆箱为内置类型。\n// var.xxxValue()对var进行类型转换int a = 5;System.out.println(a.floatValue()); // 5.0// type.parseInt(String str, int radix)将str转换成radix进制的type类型数据System.out.println(Integer.parseInt(&quot;5&quot;));     // 5System.out.println(Integer.parseInt(&quot;5&quot;, 2));  // 101// type.valueOf(int num, int radix)// type.valueOf(String str, int radix)获取第一个参数，转换成radix进制并以type类型输出System.out.println(Double.valueOf(5));         // 5.0System.out.println(Integer.parseInt(&quot;5&quot;, 2));  // 101// var.toString() / Integer.toString(int var)返回string类型的varSystem.out.println(a.toString());       // &quot;5&quot;// var.compareTo(NumberClass num)比较两者大小，如果var&lt;num，则返回-1System.out.println(a.compareTo(4));     // 1// var.equals(object num)如对象不为Null，且与方法的参数类型与数值都相等返回true，否则返回falseshort b = 5;System.out.println(a==b);           // trueSystem.out.println(a.equals(b));    // false\n\nMath类中则包含了常见的数学运算，可以直接使用Math.method()进行调用。\nint a = 9;int b = 10;Math.min(a, b);     // 9Math.pow(a, 2);     // 81Math.sqrt(a);       // 3\n\n\nString类定义有两种定义方式，分别是直接定义和使用类创建对象。\nString s1 = &quot;hello&quot;;String s2 = &quot;hello&quot;;String s3 = s1;String s4 = new String(&quot;hello&quot;);String s5 = new String(&quot;hello&quot;);\n其中直接定义的会储存在公共池中，而实例化的会在堆中开辟空间并初始化。即上述代码中s1,s2,s3指向同一个地方，三者中任意一个改变会影响另外两个；s4,s5即使内容相同，但是是两个独立的内存区域。\n常用函数\nint length() – 用于得到字符串的长度\nString concat(String str) / str + str – 拼接字符串\nchar charAt(int index) – 相当于Python中str[index]\nboolean equals(String str) – 比较两个字符串内容是否一样\nint indexOf(char ch, int startIndex = 0)/ int indexOf(String substr, int startIndex = 0) – 从startIndex查找第一次出现ch / substr的下标\nint compareTo(String str) – 按字典序比较两个字符串\n==比较的是地址，equals比较的是内容！\n\n\n\n\nStringBuilder类String的问题String类是不可改变的，即字符串常量，这就意味着每一个字符串都是独立占用空间的。比如如下的代码\nString s = &quot;a&quot; + &quot;b&quot; + &quot;c&quot;;\n在使用String类时，由于”a”，”b”，”c”三者不同，所以占用三个内存区域；然后执行”a” + “b”生成”ab”又要占用一个内存区域；最后保存”abc”至s又要占用一个。所以上述代码占用了五个内存空间，非常浪费。\nStringBuilder然而使用StringBuilder后，会先开辟16个单元，然后操作都会基于这16个单元进行。这样自始至终都只使用了一个内存区域。当16个单元不够用时，又会进行扩容，以求使用一块内存区域容纳更多内容。\n\nString的底层是final byte[]，而StringBuilder底层是byte[]。\n\n构造方法StringBuilder s1 = new StringBuilder();         // &quot;&quot;StringBuilder s2 = new StringBuilder(&quot;abc&quot;);    // &quot;abc&quot;\n\n常用方法\npublic StringBuffer append(Type var) – 将var追加到后面，var可以是任意的类型！\npublic StringBuffer reverse() – 翻转\npublic delete(int start, int end) – 删除区间内容\npublic insert(int offset, String str) – 插入\npublic replace(int start, int end, String str) – 替换\n\n上述几个方法都是返回this（即对原数据进行了修改），所以无需设置返回值。\n\nint capacity() – 返回分配的单元大小\nint length() – 返回内容的长度\nchar charAt(int idx) – 返回指定位置的元素\nint indexOf(String str) – 返回首次出现的位置\nvoid setCharAt(int index, char ch) – 设置指定位置的值\nString substring(int start, int end) – 返回子序列\n\n\nJava方法按值传递Java和C++/Python不同，只有按值传递，没有按引用传递。但是，由于Java有引用变量，所以引用变量按值传递的效果和按引用传递是一样的。\n即内置数据类型在函数中修改，并不会影响原数据；引用数据类型在函数中修改，会影响原数据。\n方法重载创建另一个有相同名字但参数不同的方法，系统会根据调用时传入参数的个数、类型等的对应关系选择合适的函数进行调用。\n这些不同的参数个数、类型等被称作参数列表。重载的方法必须拥有不同的参数列表。不能仅仅依据修饰符或者返回类型的不同来重载方法。\n构造方法当一个对象被创建时候，构造方法用来初始化该对象。构造方法和它所在类的名字相同，但构造方法没有返回值。Java 自动提供了一个默认构造方法，默认构造方法的访问修饰符和类的访问修饰符相同(类为 public，构造函数也为 public；类改为 protected，构造函数也改为 protected)。一旦你定义了自己的构造方法，默认构造方法就会失效。\n可变参数在参数列表中最多只能有一个可变参数，且一定要位于最后一个参数。其格式为type... vars。\nint max(int... nums)&#123;    int big = Integer.MIN_VALUE;    for(int num: nums)&#123;        if(num&gt;big)&#123;            big = num;        &#125;    &#125;    return big;&#125;\n\nfinalize() 方法Java 允许定义这样的方法，它在对象被垃圾收集器析构(回收)之前调用，这个方法叫做 finalize()，它用来清除回收对象。\n在 finalize() 方法里，你必须指定在对象销毁时候要执行的操作。\nJava 的内存回收可以由 JVM 来自动完成。如果你手动使用，则可以使用上面的finalize() 方法。\n\nJava数组数组创建动态初始化int[] array0 = new int[10];int[] array1;array1 = new int[10];\n\n静态初始化int[] array0 = new int[] &#123;1,2,3&#125;;int[] array1 = &#123;1,2,3&#125;;int[] array2;// array2 = &#123;1,2,3&#125;;    falsearray2 = new int[] &#123;1,2,3&#125;;\n\njava.util.Arrays提供的所有方法都是static的，可以用于操作数组。\n\npublic static int binarySearch(Type[] a, type key)\n\n用二分查找算法在给定数组中搜索给定值的对象(Byte,Int,double等)。数组在调用前必须排序好的。如果查找值包含在数组中，则返回搜索键的索引；否则返回 (-(插入点) - 1)。\n\npublic static boolean equals(Object[] a, Object[] a2)\n\n如果两个数组包含相同数量的元素，并且两个数组中的所有相应元素对都是相等的，则认为这两个数组是相等的。换句话说，如果两个数组以相同顺序包含相同的元素，则两个数组是相等的。\n\npublic static void fill(Type[] a, type val)\n\n将指定的 val 值分配给指定 type 型数组指定范围中的每个元素。\n\npublic static void sort(Object[] a)\n\n对指定对象数组根据其元素的自然顺序进行升序排列。\n\n包装类基本数据类型使用非常方便，但是缺少能够对这些数据进行操作的方法。因此我们可以用一个类将这些数据类型包裹起来，然后添加上额外的方法以便于操控。那么此时，这种类被称为包装类。\n使用包装类后，将基本数据类型变为引用数据类型，但是增加了更多方便的操控手段。\n装箱与拆箱装箱：基本类型&rarr;引用类型\nInteger a = new Integer(10);        // 使用构造方法Integer b = new Integer(&quot;20&quot;);      Integer c = Integer.valueOf(30);    // 使用静态方法Integer d = Integer.valueOf(&quot;40&quot;);\n\n拆箱：引用类型&rarr;基本类型\nint aa = a.intValue();\n\n自动装箱与自动拆箱Integer a = 10;     // 自动装箱a = a + 20;         // 先自动拆箱，取出10，计算后得到30，再自动装箱\n\n\nIO, Stream和File","categories":["Java","概念"],"tags":["概念","Java"]},{"title":"Java进阶","url":"/2021/06/06/Java%E8%BF%9B%E9%98%B6/","content":"代码块静态代码快静态代码块在类被加载的时候就运行了，而且只运行一次，并且优先于各种代码块以及构造函数。如果一个类中有多个静态代码块，就会按照书写的顺序执行。一般如果有些代码需要在项目启动的时候执行，这时就需要静态代码快。\npublic class CodeBlock&#123;    static &#123;        // 静态代码块    &#125;&#125;\n\n构造代码块构造代码块在创建对象的时候被调用，每创建一次对象都会调用一次，但是优先于构造函数执行，需要注意的是，构造代码块不是优先于构造函数执行的，而是依托于构造函数，也就是说，如果你不实例化对象，构造代码块是不会执行的。\npublic class CodeBlock&#123;    &#123;        System.out.println(&quot;构造代码块&quot;);    &#125;    public CodeBlock()&#123;        System.out.println(&quot;无参数构造函数&quot;);    &#125;    public CodeBlock(int i)&#123;        System.out.println(&quot;有参数构造函数&quot;);    &#125;&#125;/*    上述代码等同于下面的代码*/public class CodeBlock&#123;    public CodeBlock()&#123;        System.out.println(&quot;构造代码块&quot;);        System.out.println(&quot;无参数构造函数&quot;);    &#125;    public CodeBlock(int i)&#123;        System.out.println(&quot;构造代码块&quot;);        System.out.println(&quot;有参数构造函数&quot;);    &#125;&#125;\n\n\n访问控制符\n\n\n控制符名称\n类内\n同包其他类\n同包父子类\n不同包父子类\n不同包其他类\n\n\n\npublic\nY\nY\nY\nY\nY\n\n\nprotected\nY\nY\nY\nY/N\nN\n\n\ndefault\nY\nY\nY\nN\nN\n\n\nprivate\nY\nN\nN\nN\nN\n\n\n\n注意，protected比较繁琐：\n\n在同一个包内，无论如何都是可以访问的\n在不同包内，如果是不同的类，则不可访问；如果是子类，那么可以继承父类的protected内容，但是不能访问父类的这些内容\n\n\n继承继承关键字extends使用extends关键字实现继承。\npublic class Animal&#123;    private String name;    private int age;    public Animal(String myName, int myAge)&#123;        name = myName;        age = myAge;    &#125;    public void show()&#123;        System.out.println(&quot;name:&quot;+name+&quot;, age:&quot;+age);    &#125;&#125;class Tiger extends Animal&#123;    private double weight;    public Tiger(String myName, int myAge, double myWeight)&#123;        super(myName, myAge);        weight = myWeight;    &#125;&#125;\n\nimplements使用 implements 关键字可以变相的使java具有多继承的特性，使用范围为类继承接口的情况，可以同时继承多个接口。\npublic interface A &#123;    public void eat();    public void sleep();&#125; public interface B &#123;    public void show();&#125; public class C implements A,B &#123;&#125;\n\nsuper Vs this可以通过super关键字来实现对父类成员的访问，用来引用当前对象的父类。\n而this关键字实现对自己成员的访问。\nclass Animal &#123;  void eat() &#123;    System.out.println(&quot;animal : eat&quot;);  &#125;&#125; class Dog extends Animal &#123;  void eat() &#123;    System.out.println(&quot;dog : eat&quot;);  &#125;  void eatTest() &#123;    this.eat();   // this 调用自己的方法    super.eat();  // super 调用父类方法  &#125;&#125; public class Test &#123;  public static void main(String[] args) &#123;    Animal a = new Animal();    Dog d = new Dog();    a.eat();            // animal: eat    d.eat();            // dog: eat    d.eatTest();        // dog:eat \\n animal: eat  &#125;&#125;\n\n\n\n继承类型Java中不能实现多继承，即\n\n\n继承特性\n子类拥有父类的非private属性和方法\n子类可以拥有父类没有的属性和方法，父类无法访问\n子类可以重新实现父类提供的方法\n\n构造子类是不继承父类的构造方法或者构造函数的，它只是调用（隐式或显式）。如果父类的构造器带有参数，则必须在子类的构造器中显式地通过 super 关键字调用父类的构造器并配以适当的参数列表。\n如果父类构造器没有参数，则在子类的构造器中不需要使用 super 关键字调用父类构造器，系统会自动调用父类的无参构造器。\n\n重写(Override)&amp;重载(Overload)重写和重载是Java多态的表现形式。重写体现了父类和子类之间的多态，而重载则是多态的具体表现形式。\n重写重写是子类对父类的允许访问的方法的实现过程进行重新编写, 返回值和形参都不能改变。即外壳不变，核心重写。\n重写的好处在于子类可以根据需要，定义特定于自己的行为。 也就是说子类能够根据需要实现父类的方法。\n\n重写的规则\n\n参数列表必须与原函数相同\n返回类型可以不同，但是必须是父类返回值的派生类class Animal&#123;    Animal func(...)&#123;        ...    &#125;&#125;class Dog extends Animal&#123;    Dog func(...)&#123;    // 此处可以返回Animal或者Dog        ...    &#125;&#125;\n访问权限不能比父类的权限更低\nfinal修饰的不能被重写；static修饰的不能被重写，但是可以被再次声明\n构造方法不能被重写\n使用super调用父类中的“被重写函数”，用this或直接使用函数名来调用当前类的“重写函数”class Animal&#123;    void show())&#123;        System.out.println(&quot;Animal&quot;);    &#125;&#125;class Dog extends Animal&#123;    void show()&#123;        System.out.println(&quot;Dog&quot;);    &#125;    void func()&#123;        show();           // Dog        this.show();      // Dog        super.show();     // Animal    &#125;&#125;\n\n\n重载重载是在一个类里面，方法名字相同，而参数不同。返回类型可以相同也可以不同。\n每个重载的方法都必须有一个独一无二的参数类型列表。\n\n重载的规则\n\n必须改变参数列表\n可以改变返回类型，也可以不改变\n可以改变访问权限\n能够在同一个类或者子类中被重载\n只改变返回值，不改变参数列表并不能视为重载int func(int a, int b);   double func(int a, int b);        // 由于参数列表未变，所以不是重载int func(int a, int b, int c);    // 参数数量变化可以视为参数列表变化int func(float a, float b);       // 参数类型变化可以视为参数列表变化\n\n\n\n多态多态就是指程序中定义的引用变量所指向的具体类型和通过该引用变量发出的方法调用在编程时并不确定，而是在程序运行期间才确定，即一个引用变量倒底会指向哪个类的实例对象，该引用变量发出的方法调用到底是哪个类中实现的方法，必须在由程序运行期间才能决定。因为在程序运行时才确定具体的类，这样，不用修改源程序代码，就可以让引用变量绑定到各种不同的类实现上，从而导致该引用调用的具体方法随之改变，即不修改程序代码就可以改变程序运行时所绑定的具体代码，让程序可以选择多个运行状态，这就是多态性。\n多态存在的三个必要条件\n继承：多态是多个子类对同一父类的不同体现，所以要有父类和子类\n重写：当使用多态方式调用方法时，首先检查父类中是否有该方法，如果没有，则编译错误；如果有，再去调用子类的同名方法。因此需要重写父类的方法\n父类引用指向子类对象：Parent p = new Child();\n\n多态的特点\n多态成员变量：编译运行看左边\n多态成员方法：编译看左边，运行看右边\n\nclass Animal &#123;    public String name = &quot;animal&quot;;    void show() &#123;        System.out.println(&quot;Animal&quot;);    &#125;&#125;class Cat extends Animal &#123;    public String name = &quot;cat&quot;;    void show() &#123;        System.out.println(&quot;Cat&quot;);    &#125;    void unique() &#123;        System.out.println(&quot;meow meow&quot;);    &#125;&#125;public class Main &#123;    public static void main(String[] args) &#123;        Animal a = new Cat();        a.show();                       // Cat &lt;- 对于方法看右边，即Cat中的方法        // a.unique(); Animal中没有定义unique，所以报错        System.out.println(a.name);     // animal &lt;- 对于成员看左边，即Animal中的成员        Cat cat = (Cat) a;        cat.show();                     // Cat        cat.unique();                   // meow meow        System.out.println(cat.name);   // cat    &#125;&#125;\n\n转型具体内容可以参考这里。\n\n虚函数Java中并没有虚函数，其普通函数就类似于C++中的虚函数，进行动态绑定。如果不希望某个函数有动态绑定，则使用final进行修饰即可。\n在C++中，如果不使用virtual，那么如果定义父类 变量 = new 子类()，那么在调用父类方法时，只会使用父类的函数。但是，如果使用了virtual，那么调用父类方法时会自动查找到子类重写的方法。\n即不使用virtual时，只根据定义的类型进行调用，而使用virtual后会根据指向的类型进行调用。\nclass Father&#123;  public:    void test()&#123;      cout&lt;&lt;&quot;father...&quot;&lt;&lt;endl;    &#125;&#125;class Son: public Father&#123;  public:    void test()&#123;      cout&lt;&lt;&quot;son...&quot;&lt;&lt;endl;    &#125;&#125;Father *p1 = new Father();Father *p2 = new Son();p1-&gt;test();   // father...p2-&gt;test();   // father...\n\nclass Father&#123;  public:    virtual void test()&#123;      cout&lt;&lt;&quot;father...&quot;&lt;&lt;endl;    &#125;&#125;class Son: public Father&#123;  public:    void test()&#123;      cout&lt;&lt;&quot;son...&quot;&lt;&lt;endl;    &#125;&#125;Father *p1 = new Father();Father *p2 = new Son();p1-&gt;test();   // father...p2-&gt;test();   // son...\n\n\n抽象类抽象类除了不能实例化对象之外，类的其它功能依然存在，成员变量、成员方法和构造方法的访问方式和普通类一样。由于抽象类不能实例化对象，所以抽象类必须被继承，才能被使用。\nabstract同样可以用来声明抽象方法，抽象方法只包含一个方法名，而没有方法体。抽象方法没有定义，方法名后面直接跟一个分号，而不是花括号。\npublic abstract void func();\n\n\n\n如果一个类包含任意的abstract修饰的方法，则该类也必须被声明为抽象类；\n抽象类的子类必须给出抽象类中的抽象方法的具体实现，除非该子类也是抽象类。\n\n\n\n接口接口是抽象方法的集合，相当于是多种类的统一规范。\n接口并不是类，但是类可以通过继承接口来实现这些抽象方法。类描述对象的属性和方法。接口则包含类要实现的方法。\n除非实现接口的类是抽象类，否则该类要定义接口中的所有抽象方法。\n接口无法被实例化，但是可以被实现。一个实现接口的类，必须实现接口内所描述的所有方法，否则就必须声明为抽象类。\n接口与类的区别\n接口不能用于实例化对象。\n接口没有构造方法。\n接口不能包含成员变量，除了 static 和 final 变量。\n接口不是被类继承了，而是要被类实现。\n接口支持多继承。\n\n\n在 Java 8 之前接口只能包含 public abstract 方法，但是在 Java 8 之后，可以实现 private, default 和 static 方法。\n\n接口特性\n接口是隐式抽象的，即定义interface时加不加abstract都行\n接口中每一个方法是隐式抽象的，即加不加abstract都行 接口中方法是隐式抽象的，如果不写abstract，则默认为抽象方法；如果想定义类似static和default方法，则一定要写上关键字。\n接口中每一个方法是公有的，即加不加public都行 接口中方法是隐式公开的，如果不写public，则默认为public方法；如果想定义private，则一定要写上关键字。\n接口中可以含有变量，但是接口中的变量会被隐式的指定为 public static final 变量\n\n接口的声明[显示度] interface 接口名 [extends 其他接口]&#123;  // 四种方法均可行  public abstract void method1();  public void method2();  abstract void method3();  void method4();&#125;\n\n接口的实现/*  定义接口*/public interface Animal&#123;  void eat();  void sleep();&#125;\n\n使用 implements 来实现接口。\n/*  使用类实现接口*/public class Cat implements Animal&#123;  void eat()&#123;    System.out.println(&quot;eating...&quot;);  &#125;  void sleep()&#123;    System.out.println(&quot;zzz...&quot;);  &#125;  public static void main(String args[])&#123;    Cat c = new Cat();    c.eat();    c.sleep();  &#125;&#125;\n\n一个class可以同时实现多个interface，但是有一些规则：\n\n如果多个接口有同名的抽象方法，那么只需要实现一次\n如果存在冲突的默认方法，则必须要对默认方法进行重写\n如果一个class的父类方法和interface的默认方法冲突，那么会优先选择父类方法\n\n\n接口的继承// 文件名: Sports.javapublic interface Sports&#123;   public void setHomeTeam(String name);   public void setVisitingTeam(String name);&#125; // 文件名: Football.javapublic interface Football extends Sports&#123;   public void homeTeamScored(int points);   public void visitingTeamScored(int points);   public void endOfQuarter(int quarter);&#125;\n在上述代码中，如果某个 class 实现了 Football 接口，那么需要实现一共5个方法。\n接口也是可以多继承的，但是有一些规则：\n\n如果多个父接口中抽象方法冲突，没有关系。\n如果多个父接口中默认方法冲突，则必须重写该默认方法，且仍然要带着default关键字。\n\n\n接口常量在接口中，不能定义普通的成员变量，只能定义public static final常量。这同样是因为接口的多继承原因，即如果多个接口有同名的成员变量，那么实现接口的类会出现冲突。\ndefault默认方法在 JAVA 8 之后加入了默认方法，为的就是解决接口升级问题：比如接口中定义了一个抽象方法，然后某一个类实现了该接口；如果更新接口，加入了新的抽象方法，那么之前的类就需要实现新添加的方法，这非常麻烦且不符合业务要求。\n为此，引入了默认方法：通过默认方法，可以在接口中直接实现该方法，如果后面的类需要重写，直接重写即可；如果后面的类不需要重写，那么也不会报错。\npublic interface MyInterface&#123;    public abstract void func1();    public default void func2() &#123;      // 一些功能    &#125;&#125;\n\nstatic静态方法在接口中定义静态方法时需要实现该方法。\npublic interface InterfaceStatic&#123;    public static void myStatic()&#123;        System.out.println(&quot;这是一个静态方法&quot;);    &#125;&#125;\n\n我们会定义某个类，来应用该接口。在该类中，需要实现所有的抽象方法，但是对于static方法，不能在该类中实现/重写。\n\n因为某一个类可以实现多个接口，如果多个接口中出现了同名的static，那么在main函数中通过对象.静态方法(参数);就会产生冲突，不知道该使用该类实现的哪一个接口。\n\n那么在main函数中，如何调用该接口的静态方法呢？\n答案就是在main函数中直接使用接口名.静态方法(参数);的方式进行调用即可。\nprivate私有方法在接口中，某些非抽象方法可能会需要调用函数，那么我们可以将函数定义为private的，这样这些函数可以在接口内帮助实现方法，同时不会被外部错误的调用。\n私有方法分为：普通私有方法(用于被default方法调用)和静态私有方法(用于被static方法调用)\n\n枚举EnumJava 枚举是一个特殊的类，一般表示一组常量。\nenum Color&#123;  RED, GREEN, BLUE&#125;public class Test&#123;    // 执行输出结果    public static void main(String[] args)    &#123;        Color c1 = Color.RED;        System.out.println(c1);   // RED    &#125;&#125;\n\nEnum的实现每个枚举都是通过 Class 在内部实现的，且所有的枚举值都是 public static final 的。\n以上的枚举类 Color 转化在内部类实现:\nclass Color&#123;     public static final Color RED = new Color();     public static final Color BLUE = new Color();     public static final Color GREEN = new Color();&#125;\n\njava.lang.Enum\nvalues() 返回枚举类中所有的值。\nordinal()方法可以找到每个枚举常量的索引，就像数组索引一样。\nvalueOf()方法返回指定字符串值的枚举常量。\n\nenum Color&#123;    RED, GREEN, BLUE;&#125; public class Test&#123;    public static void main(String[] args)    &#123;        // 调用 values()        Color[] arr = Color.values();         // 迭代枚举        for (Color col : arr)        &#123;            // 查看索引            System.out.println(col + &quot; at index &quot; + col.ordinal());        &#125;         // 使用 valueOf() 返回枚举常量，不存在的会报错 IllegalArgumentException        System.out.println(Color.valueOf(&quot;RED&quot;));        // System.out.println(Color.valueOf(&quot;WHITE&quot;));    &#125;&#125;\n\nEnum方法和普通 class 一样，可以定义各种方法和属性。\n构造函数只能使用 private 访问修饰符，所以外部无法调用。\nenum Color&#123;    RED, GREEN, BLUE;     // 构造方法    private Color()    &#123;        System.out.println(&quot;Constructor called for : &quot; + this.toString());    &#125;    // 普通方法    public void colorInfo()    &#123;        System.out.println(&quot;Universal Color&quot;);    &#125;&#125;\n\n如果枚举类具有抽象方法，则枚举类的每个实例都必须实现它。\nenum Color&#123;  public abstract String getColor();//定义抽象方法  RED&#123;      public String getColor()&#123;          return &quot;红色&quot;;      &#125;  &#125;,  GREEN&#123;      public String getColor()&#123;          return &quot;绿色&quot;;      &#125;  &#125;,  BLUE&#123;      public String getColor()&#123;          return &quot;蓝色&quot;;      &#125;  &#125;;&#125;\n\n内部类非静态内部类非静态内部类可以直接定义在一个类内。由于在该类内部，所以可以访问该类private的内容。\n比如：战斗成绩只有在一个英雄对象存在的时候才有意义。所以实例化 Score 的时候，必须建立在一个存在的英雄 Hero 的基础上。\npublic class Hero&#123;    private String name;    public Hero(String name)&#123;        this.name = name;    &#125;    /*内部类*/    class Score&#123;        int kill = 0;        public void killOne()&#123;            this.kill += 1;        &#125;        public void showScore()&#123;            System.out.println(this.name + &quot;killed&quot; + this.kill);        &#125;    &#125;    public static void main(String args[])&#123;        Hero h = new Hero(&quot;timo&quot;);        Score s = h.new Score();        s.killOne();        s.showScore();  // timo killed 1    &#125;&#125;\n\n静态内部类在类的内部定义一个静态的类，这意味着该内部类对所有的外部类对象都生效。\n比如敌方水晶，当敌方水晶没有血的时候，己方所有英雄都取得胜利，而不只是某一个具体的英雄取得胜利。\n与非静态内部类不同，静态内部类水晶类的实例化时，不需要一个外部类的实例为基础，可以直接实例化。\n因为没有一个外部类的实例，所以在静态内部类里面不可以访问外部类的实例属性和方法。这意味着，对于外部类的静态内容还是可以进行访问调用的。\npublic class Hero &#123;    public String name;      private static void battleWin()&#123;        System.out.println(&quot;battle win&quot;);    &#125;         /*内部静态类*/    static class EnemyCrystal&#123;        int hp=5000;        public void checkIfVictory()&#123;            if(hp==0)&#123;                Hero.battleWin(); // 可以直接访问外部类的静态内容                // 不可以访问外部类的非静态内容，因为非静态内容意味着和实例化对象有关，而内部静态类是共享的                // System.out.println(name + &quot; win this game&quot;);             &#125;        &#125;    &#125;         public static void main(String[] args) &#123;        //实例化静态内部类        Hero.EnemyCrystal crystal = new Hero.EnemyCrystal();        crystal.checkIfVictory();    &#125;&#125;\n\n匿名类在声明的同时实例化一个类。对于抽象类或者接口，可以实例化一个抽象类并实现其中的抽象方法。\n格式:\nclassName var &#x3D; new className()&#123;    &#x2F;&#x2F; 匿名类方法&#125;;\n\nabstract class Abs&#123;    public abstract void func();&#125;public class Main&#123;    public static void main(String args[])&#123;        Abs abs = new Abs()&#123;            public void func()&#123;                System.out.println(&quot;实现匿名类中的方法&quot;);            &#125;        &#125;;      // 一定要注意，匿名类定义时格式        abs.func();        System.out.println(abs);  // 由于是匿名类，所以由编译器自动分配实例化的名称    &#125;&#125;\n\n本地类相当于是一种有名字的匿名函数。\n内部类与匿名类不一样的是，内部类必须声明在成员的位置，即与属性和方法平等的位置。即 内部类需要定义在类的内部。\n本地类和匿名类一样，直接声明在代码块里面，可以是主方法，for循环里等等地方。即 本地类和匿名类可以定义在函数中，如 main 函数，不一定非要在类的定义内。\nabstract class Abs&#123;    public abstract void func();&#125;public class Main&#123;    public static void main(String args[])&#123;        class Local extends Abs&#123;            public void func()&#123;                System.out.println(&quot;实现匿名类中的方法&quot;);            &#125;        &#125;                Local l = new Local();        l.func();    &#125;&#125;","categories":["Java","概念"],"tags":["概念","Java"]},{"title":"Redis进阶","url":"/2021/05/19/Redis%E8%BF%9B%E9%98%B6/","content":"事务&amp;锁Redis 事务是一个单独的隔离操作，所有命令序列化、按序执行，不会被插手打断。之所以要引入事务，就是为了将多个小操作合并成一个大操作，且“一次性”执行完整个大操作。\n基本步骤\nmulti – 用于组合小操作，此时只是组合，并未执行。如果出现错误，则所有的操作均被抛弃，无法运行任何一个。\nexec – 执行队列。如果有错误，则只会执行正确的步骤，并不会像MySQL一样回滚。\ndiscard – 放弃之前的操作。\n\n解决冲突由于现实生活中都是并发执行的，所以可能出现多个对同一资源的诉求，这被称作冲突。解决冲突的方法就是加锁。\n乐观锁乐观锁认为资源不会轻易受污染，所以放任多个线程同时访问，如果访问结束后出现冲突再解决。\n具体方法是：使用版本号，对资源操作后更新版本号，其他已经占用资源的线程如果想更改资源，发现版本号不同后就无法操作。\n悲观锁悲观锁认为资源很容易就被污染，所以每一步操作都要加以限制。\n具体方法就是：一旦某个进程控制了资源，就给他加上锁，别的进程就只能等待。当使用完资源后，进程再解锁，别的进程再开始竞争。\n其逻辑简单，但是相当于是串行实现多线程，效率低下。\n代码实现使用multi开启组队模式，组队完成后可以使用exec进行执行或discard放弃组队。而 Redis 中是不支持直接使用悲观锁的，所以加锁都是乐观锁。具体操作就是使用watch &lt;key&gt;完成对某个数据的监视，在事务执行前，如果被监视的数据发生了变化，则事务不能执行。\n三大特性\n单独隔离操作\n无隔离级别\n不保证原子性 – 只能保证不被打断，一旦出错是不会rollback的\n\n\nPipelineRedis客户端执行一条命令分为以下四个步骤:\n\n发送命令\n命令排队\n命令执行\n返回结果\n\n其中,第一步+第四步称为Round Trip Time(RTT,往返时间)。\n如果想要执行多个步骤，则需要耗费多个RTT，如果能把这些步骤在一个RTT内一起发送，就会非常有效率。这样的实现机制就是Pipeline。\nPipeline和事务的差别\nPipeline是将命令打包好一起发送，服务器接受后再一条一条的执行，处理完再将这些命令的结果一并返回；但是事务是在组队后发送多个操作，服务器在组队完毕后一口气执行完，最后再返回结果。(pipeline是将命令打包一次发送，服务器多次执行；事务是命令分开发送，服务器一并执行)\npipeline只不过是将命令一起发送，对服务器而言是不知道客户端是否使用了pipeline；而事务是服务器支持的，客户端的命令发送仍然是分离的，但是服务器会将组队的一起执行。(pipeline是客户端行为，事务是服务端行为)\n执行事务时会阻塞其他任务，而pipeline不会\n事务是原子性的，pipeline不是\n\n\n持久化RDBRDB (Redis Database)是在指定时间间隔内将数据快照(snapshot)从内存中转移到磁盘中，恢复时将快照转至内存中。\nRedis中RDB的配置默认在开启服务器的路径下生成一个dump.rdb文件，用于保存快照，其中可以设置时间间隔和达到的目标，如3600秒内更新了100个数据才会进行持久化。\n\n如果3600s内更新了101个文件，那么前100个会进行持久化，多余的1个会算入下一个3600s内。\n\n还有一些设置是否自动持久化、磁盘无法写入是否终止等操作的，可以自己摸索。\n如何持久化Redis会单独创建一个子进程用于持久化，会先将数据写入一个临时文件，当持久化结束后再用临时文件替换上一次持久化的文件。整个过程中，主进程不进行任何IO操作。\n由于需要将临时文件全部写入后才会更换原来的持久化文件，如果当写临时文件时出现宕机等，导致临时文件没有写完，那么持久化文件仍保存了上一次的数据，新的数据就丢失了。\n优缺点优点：\n\n适合大规模数据，因为只需要父进程fork一个子进程，然后就不用管子进程\n节省磁盘空间\n恢复速度快\n\n缺点：\n\nfork需要生成临时文件，会占用额外空间\n最后一次持久化后的数据可能丢失\n虽然使用写时拷贝技术，但是如果数据庞大时还是比较消耗性能\n\nAOFAOF (Append Only File)会以日志形式记录每个写操作(增量保存，不会记录读操作)，只许追加文件但不可以改写文件。Redis启动时会将日志内容重新按序执行一次以恢复/加载数据。\n默认情况下AOF是不开启的，如果RDB和AOF同时开启，Redis会选择使用不会丢失信息的AOF。\nAOF同步频率\nappendfsync always：始终同步，每次写入操作都会记录到日志中，性能差但是完整性好\nappendfsync everysec：每秒同步一次\nappendfsync no：不主动同步，同步的时机由OS控制\n\nRewrite数据压缩将多个步骤压缩成较少的步骤，如set k1 v1和set k2 v2合并成mset k1 v1 k2 v2进行保存。\n当AOF文件持续增长而过大时，会fork一个新的进程来重写文件(先创建临时文件再覆盖)，实际上就是把rdb的快照以二进制形式加在新的aof的头部，作为历史数据汇总，替换流水账。\n流程\n客户端写命令被追加到AOF缓冲区\nAOF缓冲区根据同步的频率将内存&rarr;磁盘\nAOF文件超过大小时进行rewrite\nRedis下次启动时会加载AOF的写操作完成数据加载\n\n优缺点优点：\n\n备份机制更加稳健，丢失数据概率低\n日志文件易读，且有日志文件纠错\n\n缺点：\n\n占用磁盘空间\n恢复和加载数据慢\n同步频率设置过高会造成巨大压力\n\n选择RDB还是AOF？\n建议两者都开启，搭配使用\n如果不追求数据完整性，建议使用RDB\n不建议单独使用AOF，因为可能存在日志BUG无法恢复数据\n如果只是做内存缓存，则可以都不使用\n\n\n主从复制主机数据更新后根据配置和策略，自动同步到备机的master/slave机制，Master以写为主，Slave以读为主\n为什么要使用主从复制\n读写分离，提高效率\n容灾快速恢复：由于一般有多个从服务器(即可以从多个地方读)，所以一旦一个服务器宕机，还可以依赖别的服务器\n\n步骤\n新建多个 conf 文件\n设置 pid (windows不适用)、rdb filename、port 和 slaveof [masterIP] [masterPORT]\n启动服务redis-server &lt;conf&gt;\n启动客户端redis-cli -p &lt;port&gt;，在客户端中使用info replication可以查看主从情况\n\n如何实现数据同步\nSlave 连接上 Master 后，主动向 Master 发送请求，要求进行数据同步(Slave 主动)\nMaster 收到 Slave 请求后，进行持久化，生成rdb文件，然后把rdb文件发送给 Slave\n全量复制：Slave 通过rdb进行数据同步\n增量复制：当有请求向 Master 进行write操作，Master 处理完后发送给 Slave 进行数据同步（Master 主动）\n\n四种常用的主从方式一主多从如果从机挂了重启，数据恢复会将主机中的所有数据进行复制(sync)；如果主机挂了，从机会持续尝试和主机同步，直到主机上线。\n薪火相传构成树形结构，中间的服务器对于父节点而言是从机，对于子节点而言是主机。\n\n存在很大的问题，中间服务器宕机，则其所有从机都要停止工作\n\n反客为主如果主机挂了，可以设置一个从机为新的主机；旧的主机重启后变为从机。\n\n需要手动使用slaveof no one进行设置。这也是这种方法的缺点，需要手动控制\n\n哨兵模式相当于自动版的“反客为主”：主机挂了会自动推选一个从机。\n由于有多个从机，推举哪一个就需要有设置：\n\n设置优先级replica-priority &lt;value&gt;，value越小，优先级越高\n如果优先级一样，则选择偏移量(获取主机数据更安全的/同步率最高的)大的\n如果还是一样，则选择runid小的(随机)\n\n步骤\n新建 sentinel.conf\n设置sentinel monitor &lt;name&gt; &lt;masterIP&gt; &lt;masterPORT&gt; &lt;num&gt;\n\nname – 别名\nnum – 至少num个从机同意推举新的主机后才能推举\n\n\n\n启动哨兵模式redis-server &lt;conf&gt; --sentinel\n\n\n集群使用集群可以解决很多问题：\n\n容量不够，如何扩容redis\n提高并发量\n如果服务器挂了重启，ip可能会变。之前使用“代理主机”的方法解决，如今使用“去中心化集群”的方法解决\n\n代理主机 &amp; 去中心化集群代理主机使用代理服务器对请求进行分流\n                                    ---&gt;  server0client  --- request ---&gt;  代理(中心)  ---&gt;  server1                                    ---&gt;  server2\n\n去中心化集群每一台服务器都可以用作“代理服务器”\nclient  --- request ---&gt;  server0  &lt;---&gt;  server1                            |                |                            |                |                          server2 ------------\n\n\n水平扩容：N个redis节点可以将整个DB分解成N份，每个节点只需要存储一小部分\n可用性扩展：即使有一部分挂了，其他部分也可以正常运行\n\n使用集群注意，在Redis集群模式下，至少需要三个主机，且在分配服务器为主机的时候，会采用“主机IP尽量不同，从机和主机IP也尽量不同”的原则。\n配置文件在 conf 文件中设置如下内容：\n\ncluster-enabled yes\ncluster-config-file [file]\ncluster-node-timeout [time]\n\n开启服务器组队redis-cli --cluster create --cluster-replicas 1 [ip: port]\n\n上述代码中的1代表了配置方式，其中1表示一主一从\n\n开启客户端redis-cli -c -p [port]\n\n-c代表以集群方式开启\n\n在客户端中可以使用cluster nodes查看集群信息\nslot一个Redis集群有16384个slots，数据库中的key-value都属于某一个slot中。集群使用CRC(key)%16384来hash分配slot，集群中每个主机负责一个区域的slot (如主机1负责slot号从0到999的) 。\n注意事项\n在集群模式下插入多值时，需要使用{}# 不能使用 mset k1 v1 k2 v2 ...mset k1&#123;key&#125; v1 k2&#123;key&#125; v2 ...\ncluster中有特定的函数cluster keyslot &lt;key&gt;           # 查询key所属的slot# 下面两个操作必须要在管理指定slot的主机上查询才行cluster countkeysinslot &lt;slot&gt;  # 查询slot内的key数量cluster getkeysinslot &lt;slot&gt;    # 获取slot内key的名称\n通过设置cluster-require-full-coverage为yes可以在集群中某个节点主从机全部宕机时命令整个集群失去作用；否则集群的其他节点仍可使用。\n\n\nRedis常见的问题缓存穿透key对应的数据在数据源并不存在，每次针对此key的请求从缓存获取不到，请求都会到数据源，从而可能压垮数据源。\n具体的流程：应用服务器压力突增 &rarr; request请求的都是redis中没有的，redis命中率下降，只能查询DB &rarr; DB压力突增，被穿透\n解决方法\n\n对空值进行缓存，并设置比较短的过期时间\n使用Bitmap设置白名单\n布隆过滤器\n实时监控，在出现缓存穿透时通知工作人员，禁用某些一直攻击的黑客\n\n\n布隆过滤器\n\n理念：类似一个hash set，用来判断某个key是否在某个集合中。和一般的hash set不同的是，这个算法无需存储key的值，对于每个key，只需要k个比特位，每个存储一个标志，用来判断key是否在集合中。\n操作\n首先需要k个hash函数，每个函数可以把key散列成为1个整数\n初始化时，需要一个长度为n比特的数组，每个比特位初始化为0\n某个key加入集合时，用k个hash函数计算出k个散列值，并把数组中对应的比特位置为1\n判断某个key是否在集合时，用k个hash函数计算出k个散列值，并查询数组中对应的比特位，如果所有的比特位都是1，认为在集合中\n\n\n优点：不需要存储Key，只需要二进制bit表示\n缺点：(1)无法删除；(2)算法判断key在集合中时，有一定的概率key其实不在集合中\n\n\n缓存击穿key对应的数据存在，但在redis中过期，此时若有大量并发请求过来，这些请求发现缓存过期一般都会从DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把DB压垮\n具体的流程：应用服务器压力突增 &rarr; redis正常运行，多个request请求某一个过期的key &rarr; 多个request全部都请求DB，导致DB被击穿\n解决方法\n\n预先设置会被多次请求的key，延缓其过期时间\n实时监控，发现某个key被频繁请求，则延缓其过期时间\n使用互斥锁\n在缓存失效时，不会直接去查询DB，而是先使用如SETNX(set if not exist)等会返回“是否操作成功”的操作去设置key-value，只有当上述操作返回成功后，再去访问一次DB，同时缓存该key-value\n\n\n\n缓存雪崩当缓存服务器重启或者大量缓存集中在某一个时间段失效，这样在失效的时候，也会给DB带来很大压力\n解决方法\n\n添加多级缓存，如 nginx + redis\n使用锁/消息队列，但是效率很低，不适用高并发\n提前发现将要过期的key，提前去刷新key\n将缓存失效的时间错开，避免集中在一起失效\n\n\n分布式锁在单机中，可以使用锁实现多线程情况下数据一致性。但是在分布式情况下，多线程运行在不同机器、系统上，为单机加锁没有用。为了控制数据的一致性，需要使用分布式锁。\n要求\n互斥性：在任意时刻，只能有一个客户端有锁\n不会死锁：如果一个客户端有锁时崩溃，没有主动解锁，也能在一定时间后自动放开\n解铃还须系铃人：加锁和解锁必须是同一个主机\n加锁和解锁需要原子性\n\n实现方法基于数据库核心思想\n在数据库中创建一个表，表中包含方法名等字段，并在方法名字段上创建唯一索引，想要执行某个方法，就使用这个方法名向表中插入数据，成功插入则获取锁，执行完成后删除对应的行数据释放锁\n加锁\n想要执行某个方法，就使用这个方法名向表中插入数据。因为我们对method_name做了唯一性约束，这里如果有多个请求同时提交到数据库的话，数据库会保证只有一个操作可以成功，那么我们就可以认为操作成功的那个线程获得了该方法的锁\n解锁\n执行完成后删除对应的行数据释放锁\n问题\n\n因为是基于数据库实现的，数据库的可用性和性能将直接影响分布式锁的可用性及性能，所以，数据库需要双机部署、数据同步、主备切换；\n\n不具备可重入的特性，因为同一个线程在释放锁之前，行数据一直存在，无法再次成功插入数据，所以，需要在表中新增一列，用于记录当前获取到锁的机器和线程信息，在再次获取锁的时候，先查询表中机器和线程信息是否和当前机器和线程相同，若相同则直接获取锁；\n\n没有锁失效机制，会导致死锁。因为有可能出现成功插入数据后，服务器宕机了，对应的数据没有被删除，当服务恢复后一直获取不到锁，所以，需要在表中新增一列，用于记录失效时间，并且需要有定时任务清除这些失效的数据；\n\n不具备阻塞锁特性，获取不到锁直接返回失败，所以需要优化获取逻辑，循环多次去获取。\n\n在实施的过程中会遇到各种不同的问题，为了解决这些问题，实现方式将会越来越复杂；依赖数据库需要一定的资源开销，性能问题需要考虑。\n\n\n基于缓存(性能最高)实现思想\n\n获取锁的时候，使用setnx加锁，并使用expire命令为锁添加一个超时时间，超过该时间则自动释放锁，锁的value值为一个随机生成的UUID，通过此在释放锁的时候进行判断。\n\n获取锁的时候还设置一个获取的超时时间，若超过这个时间则放弃获取锁。\n\n释放锁的时候，通过UUID判断是不是该锁，若是该锁，则执行delete进行锁释放。(为了实现原子性，可以使用LUA脚本实现“检查锁”和“删除锁”)\n\n\n加锁和解锁\nSETNX key val：当且仅当key不存在时，set一个key为val的字符串，返回1；若key存在，则什么都不做，返回0。\nexpire key timeout：为key设置一个超时时间，单位为second，超过这个时间锁会自动释放，避免死锁。\n\n为了实现原子性加锁，可以使用指令set key value nx ex &lt;expireTime&gt;\n\n解锁\ndelete key：删除key\n代码\n# 连接redisredis_client = redis.Redis(...)# 获取一个锁# lock_name：锁定名称# acquire_time: 客户端等待获取锁的时间# time_out: 锁的超时时间def acquire_lock(lock_name, acquire_time=10, time_out=10):    &quot;&quot;&quot;获取一个分布式锁&quot;&quot;&quot;    identifier = str(uuid.uuid4())    end = time.time() + acquire_time    lock = &quot;string:lock:&quot; + lock_name    while time.time() &lt; end:        if redis_client.setnx(lock, identifier):            # 给锁设置超时时间, 防止进程崩溃导致其他进程无法获取锁            redis_client.expire(lock, time_out)            return identifier        elif not redis_client.ttl(lock):            redis_client.expire(lock, time_out)        time.sleep(0.001)    return False# 释放一个锁def release_lock(lock_name, identifier):    &quot;&quot;&quot;通用的锁释放函数&quot;&quot;&quot;    lock = &quot;string:lock:&quot; + lock_name    pip = redis_client.pipeline(True)    while True:        try:            pip.watch(lock)            lock_value = redis_client.get(lock)            if not lock_value:                return True            if lock_value.decode() == identifier:                pip.multi()                pip.delete(lock)                pip.execute()                return True            pip.unwatch()            break        except redis.excetions.WacthcError:            pass    return False\n\n基于zookeeper(可靠性最高)ZooKeeper是一个为分布式应用提供一致性服务的开源组件，它内部是一个分层的文件系统目录树结构，规定同一个目录下只能有一个唯一文件名。\n优缺点\n优点：具备高可用、可重入、阻塞锁特性，可解决失效死锁问题。\n缺点：因为需要频繁的创建和删除节点，性能上不如Redis方式。\n\n","categories":["Redis"],"tags":["redis"]}]